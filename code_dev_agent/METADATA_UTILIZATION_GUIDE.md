# ğŸ¯ ë©”íƒ€ë°ì´í„° í™œìš© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ë©”íƒ€ë°ì´í„°ëŠ” RAG ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ ì •í™•ë„ì™€ ë‹µë³€ í’ˆì§ˆì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ” ë©”íƒ€ë°ì´í„°ì˜ í•µì‹¬ ì—­í• 

### 1. ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
- **ì»¨í…ìŠ¤íŠ¸ ì¸ì‹**: ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë§¥ë½ì„ ì •í™•íˆ íŒŒì•…
- **ìš°ì„ ìˆœìœ„ ì„¤ì •**: ì¤‘ìš”í•œ ë¬¸ì„œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰
- **í•„í„°ë§**: ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œë¥¼ ì‚¬ì „ì— ì œì™¸

### 2. ë‹µë³€ í’ˆì§ˆ ê°œì„ 
- **ì™„ì„±ë„ ë³´ì¥**: ì™„ì „í•œ ì •ë³´ë¥¼ í¬í•¨í•œ ë¬¸ì„œ ìš°ì„  ì„ íƒ
- **ê´€ë ¨ì„± ê°•í™”**: ì§ˆì˜ì™€ ì§ì ‘ ê´€ë ¨ëœ ë¬¸ì„œ ì§‘ì¤‘
- **ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´**: ë¬¸ì„œ ê°„ì˜ ê´€ê³„ ì •ë³´ ìœ ì§€

## ğŸ“Š ë©”íƒ€ë°ì´í„° êµ¬ì¡°

### ê¸°ë³¸ ë©”íƒ€ë°ì´í„° í•„ë“œ

```python
metadata = {
    # ë¬¸ì„œ ì‹ë³„
    'section_name': 'PNS ë©”ì‹œì§€ ê·œê²©',
    'content_type': 'message_specification',
    
    # ê´€ë ¨ì„± í‘œì‹œ
    'contains_pns': True,
    'contains_purchasestate': True,
    
    # ì™„ì„±ë„ í‘œì‹œ
    'is_complete_spec': True,
    
    # ê¸°ìˆ ì  ì •ë³´
    'chunk_size': 150,
    'chunk_index': 0,
    
    # ê³„ì¸µ ì •ë³´
    'title_hierarchy': 'PNS > ë©”ì‹œì§€ ê·œê²© > Payment Notification',
    'hierarchy_level': 'medium'
}
```

### í™•ì¥ ë©”íƒ€ë°ì´í„° í•„ë“œ

```python
enhanced_metadata = {
    # ê¸°ë³¸ í•„ë“œë“¤...
    
    # ìš°ì„ ìˆœìœ„ ì •ë³´
    'priority_level': 'high',
    'search_boost': 2.0,
    
    # í‚¤ì›Œë“œ ì •ë³´
    'keyword_density': {
        'pns': 0.05,
        'purchasestate': 0.03,
        'signature': 0.02
    },
    
    # ë¶€ìŠ¤íŠ¸ íŒ©í„°
    'boost_factors': [
        'complete_specification',
        'purchase_state_related',
        'pns_related'
    ],
    
    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    'context_relevance': 0.85,
    'completeness_score': 0.95
}
```

## ğŸ› ï¸ ë©”íƒ€ë°ì´í„° í™œìš© ë°©ë²•

### 1. ë©”íƒ€ë°ì´í„° ë¶„ì„ê¸° (MetadataAnalyzer)

```python
from metadata_utilization_guide import MetadataAnalyzer

# ë¶„ì„ê¸° ì´ˆê¸°í™”
analyzer = MetadataAnalyzer()

# ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¶„ì„
doc = Document(page_content="...", metadata={...})
analysis = analyzer.analyze_document_metadata(doc)

print(f"ë‚´ìš© íƒ€ì…: {analysis['content_type']}")
print(f"ìš°ì„ ìˆœìœ„: {analysis['priority_level']}")
print(f"ì™„ì„±ë„ ì ìˆ˜: {analysis['completeness_score']:.2f}")
print(f"ë¶€ìŠ¤íŠ¸ íŒ©í„°: {analysis['search_boost_factors']}")
```

#### ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ
```
ğŸ“Š ë¬¸ì„œ ë¶„ì„ ê²°ê³¼:
  - ë‚´ìš© íƒ€ì…: message_specification
  - ìš°ì„ ìˆœìœ„: high
  - ì™„ì„±ë„ ì ìˆ˜: 0.95
  - ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„±: 0.85
  - ë¶€ìŠ¤íŠ¸ íŒ©í„°: ['complete_specification', 'purchase_state_related']
```

### 2. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰ê¸° (MetadataBasedRetriever)

```python
from metadata_utilization_guide import MetadataBasedRetriever

# ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
retriever = MetadataBasedRetriever(documents)

# ê²€ìƒ‰ ê¸°ì¤€ ì„¤ì •
search_criteria = {
    'boost_factors': ['purchase_state_related', 'complete_specification']
}

# ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰
query = "PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?"
results = retriever.search_by_metadata(query, search_criteria)

for score, doc in results:
    print(f"ì ìˆ˜: {score:.2f}, ë‚´ìš©: {doc.page_content[:50]}...")
```

#### ê²€ìƒ‰ ê²°ê³¼ ì˜ˆì‹œ
```
ğŸ” ì§ˆì˜: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?

ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼:
  1. ì ìˆ˜: 8.50
     ë‚´ìš©: | purchaseState | String | COMPLETED: ê²°ì œì™„ë£Œ / CANCELED: ì·¨ì†Œ |
     íƒ€ì…: message_specification
  
  2. ì ìˆ˜: 6.20
     ë‚´ìš©: PNS ë©”ì‹œì§€ì˜ purchaseState í•„ë“œëŠ” COMPLETED ë˜ëŠ” CANCELED ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.
     íƒ€ì…: purchase_state_info
```

### 3. ë©”íƒ€ë°ì´í„° ê°•í™”ê¸° (MetadataEnhancer)

```python
from metadata_utilization_guide import MetadataEnhancer

# ë©”íƒ€ë°ì´í„° ê°•í™”
additional_info = {
    'priority_level': 'high',
    'processing_method': 'notification_handler',
    'estimated_complexity': 'intermediate',
    'related_topics': ['message_processing', 'error_handling']
}

enhanced_doc = MetadataEnhancer.enhance_document_metadata(doc, additional_info)

# ê²€ìƒ‰ìš© ë©”íƒ€ë°ì´í„° ìƒì„±
query = "PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?"
search_metadata = MetadataEnhancer.create_search_metadata(query)
```

### 4. ë©”íƒ€ë°ì´í„° ì‹œê°í™”ê¸° (MetadataVisualizer)

```python
from metadata_utilization_guide import MetadataVisualizer

# ë©”íƒ€ë°ì´í„° ìš”ì•½ ì¶œë ¥
MetadataVisualizer.print_metadata_summary(documents)

# ê°œë³„ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶œë ¥
MetadataVisualizer.print_document_metadata(doc, show_content=True)
```

#### ì‹œê°í™” ê²°ê³¼ ì˜ˆì‹œ
```
ğŸ“Š ë©”íƒ€ë°ì´í„° ë¶„ì„ ìš”ì•½
==================================================
ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: 917
ğŸ”— PNS ê´€ë ¨ ë¬¸ì„œ: 36 (3.9%)
ğŸ“‹ ì™„ì „í•œ ë©”ì‹œì§€ ê·œê²©: 4 (0.4%)
ğŸ’° purchaseState í¬í•¨: 27 (2.9%)

ğŸ“‚ ë‚´ìš© íƒ€ì…ë³„ ë¶„í¬:
  - message_specification: 4ê°œ (0.4%)
  - purchase_state_info: 23ê°œ (2.5%)
  - general_pns: 9ê°œ (1.0%)
```

## ğŸ¯ ê³ ê¸‰ í™œìš© ê¸°ë²•

### 1. ë™ì  ë¶€ìŠ¤íŠ¸ íŒ©í„°

```python
def calculate_dynamic_boost(query: str, doc: Document) -> float:
    """ë™ì  ë¶€ìŠ¤íŠ¸ íŒ©í„° ê³„ì‚°"""
    boost = 1.0
    
    # ì§ˆì˜ íƒ€ì…ë³„ ë¶€ìŠ¤íŠ¸
    if 'purchasestate' in query.lower():
        if doc.metadata.get('contains_purchasestate', False):
            boost *= 2.0
        if doc.metadata.get('is_complete_spec', False):
            boost *= 1.5
    
    # ì™„ì„±ë„ ê¸°ë°˜ ë¶€ìŠ¤íŠ¸
    if doc.metadata.get('is_complete_spec', False):
        boost *= 1.8
    
    # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¶€ìŠ¤íŠ¸
    priority = doc.metadata.get('priority_level', 'low')
    if priority == 'high':
        boost *= 1.3
    
    return boost
```

### 2. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í•„í„°ë§

```python
def context_aware_filtering(docs: List[Document], query_context: str) -> List[Document]:
    """ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ í•„í„°ë§"""
    filtered_docs = []
    
    for doc in docs:
        # ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„± ê³„ì‚°
        context_score = calculate_context_relevance(doc, query_context)
        
        # ì„ê³„ê°’ ì´ìƒë§Œ ì„ íƒ
        if context_score > 0.5:
            filtered_docs.append(doc)
    
    return filtered_docs
```

### 3. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°

```python
def calculate_metadata_score(query: str, doc: Document) -> float:
    """ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
    score = 0.0
    
    # 1. ë‚´ìš© íƒ€ì… ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”)
    query_type = identify_query_type(query)
    if doc.metadata.get('content_type') == query_type:
        score += 5.0
    
    # 2. ì™„ì„±ë„ ì ìˆ˜
    if doc.metadata.get('is_complete_spec', False):
        score += 3.0
    
    # 3. í‚¤ì›Œë“œ ë°€ë„
    keyword_density = doc.metadata.get('keyword_density', {})
    for keyword, density in keyword_density.items():
        if keyword in query.lower():
            score += density * 10
    
    # 4. ìš°ì„ ìˆœìœ„ ë³´ë„ˆìŠ¤
    priority = doc.metadata.get('priority_level', 'low')
    if priority == 'high':
        score += 2.0
    
    return score
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ë©”íƒ€ë°ì´í„° ì¸ë±ì‹±

```python
# ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤ ìƒì„±
metadata_index = {
    'content_type': {},
    'priority_level': {},
    'boost_factors': {},
    'contains_pns': {'true': [], 'false': []},
    'is_complete_spec': {'true': [], 'false': []}
}

# ì¸ë±ìŠ¤ êµ¬ì¶•
for i, doc in enumerate(documents):
    metadata = doc.metadata
    
    # ë‚´ìš© íƒ€ì…ë³„ ì¸ë±ì‹±
    content_type = metadata.get('content_type', 'unknown')
    if content_type not in metadata_index['content_type']:
        metadata_index['content_type'][content_type] = []
    metadata_index['content_type'][content_type].append(i)
    
    # ë¶€ìŠ¤íŠ¸ íŒ©í„°ë³„ ì¸ë±ì‹±
    boost_factors = metadata.get('boost_factors', [])
    for factor in boost_factors:
        if factor not in metadata_index['boost_factors']:
            metadata_index['boost_factors'][factor] = []
        metadata_index['boost_factors'][factor].append(i)
```

### 2. ìºì‹± ì „ëµ

```python
# ë©”íƒ€ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìºì‹±
metadata_cache = {}

def get_cached_analysis(doc_id: str) -> Dict[str, Any]:
    """ìºì‹œëœ ë©”íƒ€ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    if doc_id not in metadata_cache:
        doc = get_document_by_id(doc_id)
        metadata_cache[doc_id] = analyzer.analyze_document_metadata(doc)
    
    return metadata_cache[doc_id]
```

### 3. ì ìˆ˜ ì •ê·œí™”

```python
def normalize_metadata_scores(scores: List[float]) -> List[float]:
    """ë©”íƒ€ë°ì´í„° ì ìˆ˜ ì •ê·œí™”"""
    if not scores:
        return scores
    
    min_score = min(scores)
    max_score = max(scores)
    
    if max_score == min_score:
        return [1.0] * len(scores)
    
    normalized = []
    for score in scores:
        normalized_score = (score - min_score) / (max_score - min_score)
        normalized.append(normalized_score)
    
    return normalized
```

## ğŸ”§ ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### PNS ì§ˆì˜ ìµœì í™”

```python
def optimize_pns_query(query: str, documents: List[Document]) -> List[Document]:
    """PNS ì§ˆì˜ ìµœì í™”"""
    
    # 1. ë©”íƒ€ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = MetadataAnalyzer()
    
    # 2. ì§ˆì˜ ë¶„ì„
    query_analysis = analyze_query_intent(query)
    
    # 3. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
    filtered_docs = []
    for doc in documents:
        analysis = analyzer.analyze_document_metadata(doc)
        
        # ê´€ë ¨ì„± ì²´í¬
        if not is_relevant_to_query(doc, query_analysis):
            continue
        
        # ì™„ì„±ë„ ì²´í¬
        if query_analysis['requires_complete_spec'] and not analysis['completeness_score'] > 0.8:
            continue
        
        filtered_docs.append(doc)
    
    # 4. ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
    scored_docs = []
    for doc in filtered_docs:
        score = calculate_comprehensive_score(doc, query_analysis)
        scored_docs.append((score, doc))
    
    # 5. ìƒìœ„ ê²°ê³¼ ë°˜í™˜
    scored_docs.sort(key=lambda x: x[0], reverse=True)
    return [doc for score, doc in scored_docs[:10]]
```

## ğŸ“Š ì„±ëŠ¥ ì¸¡ì •

### ë©”íƒ€ë°ì´í„° í™œìš© íš¨ê³¼ ì¸¡ì •

```python
def measure_metadata_effectiveness():
    """ë©”íƒ€ë°ì´í„° í™œìš© íš¨ê³¼ ì¸¡ì •"""
    
    # í…ŒìŠ¤íŠ¸ ì§ˆì˜
    test_queries = [
        "PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
        "signature ê²€ì¦ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
        "PNS ë©”ì‹œì§€ ê·œê²©ì„ ì•Œë ¤ì£¼ì„¸ìš”"
    ]
    
    results = {
        'with_metadata': [],
        'without_metadata': []
    }
    
    for query in test_queries:
        # ë©”íƒ€ë°ì´í„° í™œìš© ê²€ìƒ‰
        metadata_results = search_with_metadata(query)
        results['with_metadata'].append(metadata_results)
        
        # ê¸°ë³¸ ê²€ìƒ‰
        basic_results = search_without_metadata(query)
        results['without_metadata'].append(basic_results)
    
    # ì„±ëŠ¥ ë¹„êµ
    compare_performance(results)
```

## ğŸ¯ ê¶Œì¥ì‚¬í•­

### 1. ë©”íƒ€ë°ì´í„° ì„¤ê³„ ì›ì¹™
- **ëª…í™•ì„±**: ë©”íƒ€ë°ì´í„° í•„ë“œì˜ ì˜ë¯¸ê°€ ëª…í™•í•´ì•¼ í•¨
- **ì¼ê´€ì„±**: ë™ì¼í•œ ì •ë³´ëŠ” í•­ìƒ ê°™ì€ í•„ë“œì— ì €ì¥
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° í•„ë“œ ì¶”ê°€ê°€ ìš©ì´í•´ì•¼ í•¨
- **ì„±ëŠ¥**: ë©”íƒ€ë°ì´í„° ì ‘ê·¼ì´ ë¹ ë¥´ê³  íš¨ìœ¨ì ì´ì–´ì•¼ í•¨

### 2. êµ¬í˜„ ìš°ì„ ìˆœìœ„
1. **ê¸°ë³¸ ë©”íƒ€ë°ì´í„°**: contains_pns, content_type, is_complete_spec
2. **ìš°ì„ ìˆœìœ„ ë©”íƒ€ë°ì´í„°**: priority_level, boost_factors
3. **ê³ ê¸‰ ë©”íƒ€ë°ì´í„°**: keyword_density, context_relevance
4. **í™•ì¥ ë©”íƒ€ë°ì´í„°**: related_topics, complexity_level

### 3. ëª¨ë‹ˆí„°ë§ ë° ê°œì„ 
- ë©”íƒ€ë°ì´í„° í™œìš© íš¨ê³¼ ì •ê¸° ì¸¡ì •
- ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ê°œì„ 
- ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° í•„ë“œ ì¶”ê°€ ê²€í† 

## ğŸ“ ì§€ì› ë° ë¬¸ì˜

ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ê°œì„  ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ì£¼ì„¸ìš”.

---

**ì°¸ê³ **: ì´ ê°€ì´ë“œëŠ” PNS ê´€ë ¨ ì§ˆì˜ ê°œì„ ì„ ìœ„í•œ ê²ƒì´ë©°, ë‹¤ë¥¸ ë„ë©”ì¸ì—ë„ ìœ ì‚¬í•œ ë©”íƒ€ë°ì´í„° í™œìš© ì „ëµì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
