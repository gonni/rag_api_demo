"""
ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ RAG ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ ë¬¸ì„œì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ê³¼ ë‹µë³€ì„ ì œê³µí•˜ëŠ”
Context-Aware RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import re
from typing import List, Dict, Any, Tuple, Optional
from langchain.docstore.document import Document
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_community.vectorstores import FAISS
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_core.prompts import PromptTemplate


class ContextAwareRAG:
    """ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, documents: List[Document], embedding_model: str = "bge-m3:latest"):
        self.documents = documents
        self.embedding_model = embedding_model
        self.vector_store = None
        self.bm25_retriever = None
        self.ensemble_retriever = None
        self.llm = None
        
    def setup(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸš€ ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        
        # ê²€ìƒ‰ê¸° êµ¬ì¶•
        self._build_retrievers()
        
        # LLM ì´ˆê¸°í™”
        self._initialize_llm()
        
        # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        self._analyze_contexts()
        
        print("âœ… ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_retrievers(self):
        """ê²€ìƒ‰ê¸° êµ¬ì¶•"""
        print("ğŸ”§ ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...")
        
        # Vector store êµ¬ì¶•
        embeddings = OllamaEmbeddings(model=self.embedding_model)
        self.vector_store = FAISS.from_documents(self.documents, embeddings)
        
        # BM25 ê²€ìƒ‰ê¸° êµ¬ì¶•
        self.bm25_retriever = BM25Retriever.from_documents(self.documents)
        self.bm25_retriever.k = 30
        
        # ì•™ìƒë¸” ê²€ìƒ‰ê¸°
        vector_retriever = self.vector_store.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 20, "fetch_k": 50, "lambda_mult": 0.7}
        )
        
        self.ensemble_retriever = EnsembleRetriever(
            retrievers=[self.bm25_retriever, vector_retriever],
            weights=[0.6, 0.4]
        )
        
        print("âœ… ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ")
    
    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        self.llm = ChatOllama(model="exaone3.5:latest", temperature=0.3)
    
    def _analyze_contexts(self):
        """ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        print("ğŸ“Š ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
        
        # PNS ê´€ë ¨ ë¬¸ì„œ ì‹ë³„
        pns_docs = []
        for doc in self.documents:
            if self._is_pns_related(doc):
                pns_docs.append(doc)
        
        print(f"  PNS ê´€ë ¨ ë¬¸ì„œ: {len(pns_docs)}ê°œ")
        
        # ì»¨í…ìŠ¤íŠ¸ ê·¸ë£¹í•‘
        self.context_groups = self._group_by_context(pns_docs)
        
        for group_name, docs in self.context_groups.items():
            print(f"  {group_name}: {len(docs)}ê°œ ë¬¸ì„œ")
    
    def _is_pns_related(self, doc: Document) -> bool:
        """PNS ê´€ë ¨ ë¬¸ì„œ ì—¬ë¶€ í™•ì¸"""
        content_lower = doc.page_content.lower()
        metadata = doc.metadata
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ í™•ì¸
        if metadata.get('contains_pns', False):
            return True
        
        # ë‚´ìš©ì—ì„œ í™•ì¸
        pns_keywords = ['pns', 'payment notification', 'ê²°ì œì•Œë¦¼', 'ë©”ì‹œì§€ ê·œê²©']
        return any(keyword in content_lower for keyword in pns_keywords)
    
    def _group_by_context(self, docs: List[Document]) -> Dict[str, List[Document]]:
        """ì»¨í…ìŠ¤íŠ¸ë³„ ê·¸ë£¹í•‘"""
        groups = {
            'message_specifications': [],
            'purchase_state_info': [],
            'signature_verification': [],
            'general_pns': []
        }
        
        for doc in docs:
            content_lower = doc.page_content.lower()
            
            if 'purchasestate' in content_lower:
                groups['purchase_state_info'].append(doc)
            elif 'signature' in content_lower:
                groups['signature_verification'].append(doc)
            elif 'element name' in content_lower or 'parameter name' in content_lower:
                groups['message_specifications'].append(doc)
            else:
                groups['general_pns'].append(doc)
        
        return groups
    
    def query(self, question: str, max_context_docs: int = 8) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì§ˆì˜ ì²˜ë¦¬"""
        print(f"ğŸ” ì§ˆì˜ ì²˜ë¦¬: {question}")
        
        # 1. ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context_type = self._analyze_query_context(question)
        print(f"  ì»¨í…ìŠ¤íŠ¸ íƒ€ì…: {context_type}")
        
        # 2. ì»¨í…ìŠ¤íŠ¸ë³„ ê²€ìƒ‰
        relevant_docs = self._context_aware_search(question, context_type, max_context_docs)
        
        # 3. ì»¨í…ìŠ¤íŠ¸ ê°•í™”
        enhanced_context = self._enhance_context(relevant_docs, context_type)
        
        # 4. ë‹µë³€ ìƒì„±
        answer = self._generate_answer(question, enhanced_context)
        
        return {
            'question': question,
            'context_type': context_type,
            'relevant_docs': relevant_docs,
            'answer': answer,
            'context_info': {
                'total_docs': len(relevant_docs),
                'context_groups': [doc.metadata.get('content_type', 'unknown') for doc in relevant_docs]
            }
        }
    
    def _analyze_query_context(self, question: str) -> str:
        """ì§ˆì˜ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        question_lower = question.lower()
        
        if 'purchasestate' in question_lower or 'purchase state' in question_lower:
            return 'purchase_state'
        elif 'signature' in question_lower:
            return 'signature_verification'
        elif 'ë©”ì‹œì§€' in question or 'message' in question_lower:
            return 'message_specification'
        elif 'pns' in question_lower or 'payment notification' in question_lower:
            return 'general_pns'
        else:
            return 'general'
    
    def _context_aware_search(self, question: str, context_type: str, max_docs: int) -> List[Document]:
        """ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ê²€ìƒ‰"""
        # 1. ê¸°ë³¸ ì•™ìƒë¸” ê²€ìƒ‰
        base_results = self.ensemble_retriever.invoke(question)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ë³„ ìš°ì„ ìˆœìœ„ ì ìš©
        if context_type in self.context_groups:
            context_docs = self.context_groups[context_type]
            
            # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìš°ì„  ì„ íƒ
            prioritized_docs = []
            for doc in context_docs:
                if doc in base_results:
                    prioritized_docs.append(doc)
            
            # ë‚˜ë¨¸ì§€ ë¬¸ì„œ ì¶”ê°€
            remaining_docs = [doc for doc in base_results if doc not in prioritized_docs]
            prioritized_docs.extend(remaining_docs)
            
            return prioritized_docs[:max_docs]
        
        return base_results[:max_docs]
    
    def _enhance_context(self, docs: List[Document], context_type: str) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê°•í™”"""
        enhanced_parts = []
        
        # ì»¨í…ìŠ¤íŠ¸ íƒ€ì…ë³„ ì„¤ëª… ì¶”ê°€
        context_descriptions = {
            'purchase_state': "ì´ ì§ˆì˜ëŠ” PNS ë©”ì‹œì§€ì˜ purchaseState í•„ë“œì™€ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤.",
            'signature_verification': "ì´ ì§ˆì˜ëŠ” PNS ë©”ì‹œì§€ì˜ ì„œëª… ê²€ì¦ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤.",
            'message_specification': "ì´ ì§ˆì˜ëŠ” PNS ë©”ì‹œì§€ ê·œê²©ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤.",
            'general_pns': "ì´ ì§ˆì˜ëŠ” PNS(Payment Notification Service) ì¼ë°˜ ì •ë³´ì™€ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤."
        }
        
        if context_type in context_descriptions:
            enhanced_parts.append(context_descriptions[context_type])
        
        # ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
        for i, doc in enumerate(docs):
            doc_content = doc.page_content.strip()
            if doc_content:
                enhanced_parts.append(f"[ë¬¸ì„œ {i+1}]: {doc_content}")
        
        return "\n\n".join(enhanced_parts)
    
    def _generate_answer(self, question: str, context: str) -> str:
        """ë‹µë³€ ìƒì„±"""
        prompt_template = PromptTemplate(
            input_variables=["question", "context"],
            template="""
ë‹¹ì‹ ì€ PNS(Payment Notification Service) ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}

ì»¨í…ìŠ¤íŠ¸:
{context}

ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        )
        
        chain = prompt_template | self.llm
        
        try:
            response = chain.invoke({"question": question, "context": context})
            return response.content
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


class PNSQueryAnalyzer:
    """PNS ì§ˆì˜ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.query_patterns = {
            'purchase_state': [
                r'purchasestate.*?ê°’',
                r'purchase.*?state.*?ë¬´ì—‡',
                r'ê²°ì œ.*?ìƒíƒœ.*?ê°’',
                r'purchasestate.*?í¬í•¨'
            ],
            'message_specification': [
                r'ë©”ì‹œì§€.*?ê·œê²©',
                r'message.*?specification',
                r'pns.*?ë©”ì‹œì§€.*?êµ¬ì„±',
                r'ìš”ì²­.*?body.*?êµ¬ì„±'
            ],
            'signature_verification': [
                r'signature.*?ê²€ì¦',
                r'ì„œëª….*?ê²€ì¦',
                r'signature.*?verification'
            ],
            'general_pns': [
                r'pns.*?ë¬´ì—‡',
                r'payment.*?notification.*?service',
                r'ê²°ì œì•Œë¦¼.*?ì„œë¹„ìŠ¤'
            ]
        }
    
    def analyze_query(self, query: str) -> Dict[str, Any]:
        """ì§ˆì˜ ë¶„ì„"""
        query_lower = query.lower()
        
        analysis = {
            'query_type': 'unknown',
            'confidence': 0.0,
            'keywords': [],
            'suggestions': []
        }
        
        # íŒ¨í„´ ë§¤ì¹­
        max_matches = 0
        best_type = 'unknown'
        
        for query_type, patterns in self.query_patterns.items():
            matches = 0
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    matches += 1
            
            if matches > max_matches:
                max_matches = matches
                best_type = query_type
        
        analysis['query_type'] = best_type
        analysis['confidence'] = max_matches / len(self.query_patterns[best_type]) if best_type != 'unknown' else 0.0
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        analysis['keywords'] = self._extract_keywords(query)
        
        # ì œì•ˆì‚¬í•­
        analysis['suggestions'] = self._generate_suggestions(best_type, query)
        
        return analysis
    
    def _extract_keywords(self, query: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ê¸°ìˆ  ìš©ì–´
        tech_patterns = [
            r'\b[A-Z]{2,}\b',  # PNS, API ë“±
            r'\b[a-z]+[A-Z][a-zA-Z]*\b',  # purchaseState ë“±
        ]
        
        for pattern in tech_patterns:
            keywords.extend(re.findall(pattern, query))
        
        # í•œê¸€ í‚¤ì›Œë“œ
        korean_keywords = ['ë©”ì‹œì§€', 'ê·œê²©', 'ê°’', 'êµ¬ì„±', 'ìƒíƒœ', 'ê²°ì œ', 'ì„œë²„', 'ì•Œë¦¼']
        for keyword in korean_keywords:
            if keyword in query:
                keywords.append(keyword)
        
        return list(set(keywords))
    
    def _generate_suggestions(self, query_type: str, query: str) -> List[str]:
        """ì œì•ˆì‚¬í•­ ìƒì„±"""
        suggestions = []
        
        if query_type == 'purchase_state':
            suggestions.extend([
                "purchaseState í•„ë“œì˜ ê°€ëŠ¥í•œ ê°’ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”",
                "COMPLETED, CANCELED ë“±ì˜ ìƒíƒœê°’ì„ ì°¾ì•„ë³´ì„¸ìš”"
            ])
        elif query_type == 'message_specification':
            suggestions.extend([
                "ë©”ì‹œì§€ ê·œê²© í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ì„¸ìš”",
                "Element Name, Data Type, Description í•„ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”"
            ])
        elif query_type == 'signature_verification':
            suggestions.extend([
                "ì„œëª… ê²€ì¦ ë°©ë²•ê³¼ ì½”ë“œ ì˜ˆì œë¥¼ í™•ì¸í•˜ì„¸ìš”",
                "PublicKeyì™€ signature í•„ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”"
            ])
        
        return suggestions
