{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03d6764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- 유틸: 키 정규화 / 용어 추출 ---------\n",
    "_WORD_SPLIT_RE = re.compile(r\"[^\\w]+\", re.UNICODE)\n",
    "CAMEL_RE = re.compile(r\"(?<!^)(?=[A-Z])\")\n",
    "\n",
    "def normalize_key(s: str) -> str:\n",
    "    # 대소문자/구분자 정규화 (camel/snake/kebab → 토큰화 후 소문자)\n",
    "    s = s.strip()\n",
    "    s = CAMEL_RE.sub(\" \", s)\n",
    "    toks = _WORD_SPLIT_RE.split(s.lower())\n",
    "    toks = [t for t in toks if t]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "def extract_exact_keys(text: str) -> List[str]:\n",
    "    keys = []\n",
    "    # 코드값/상수/식별자 패턴들 (원문 보존)\n",
    "    patterns = [\n",
    "        r\"\\b[A-Z0-9_]{3,}\\b\",                 # E401, SINGLE_PAYMENT_TRANSACTION, MKT_ONE\n",
    "        r\"\\b[A-Za-z_]+=[A-Za-z0-9._-]+\\b\",    # KEY=VALUE\n",
    "        r'\"[A-Za-z0-9_.-]+\"\\s*:',             # \"msgVersion\":  (JSON 필드명)\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        for m in re.finditer(pat, text):\n",
    "            keys.append(m.group(0).strip('\"').rstrip(\":\"))\n",
    "    # 중복 제거, 과도한 수는 상한\n",
    "    dedup = []\n",
    "    seen = set()\n",
    "    for k in keys:\n",
    "        if k not in seen:\n",
    "            seen.add(k); dedup.append(k)\n",
    "    return dedup[:200]\n",
    "\n",
    "def extract_term_keys(title: str, body: str) -> List[str]:\n",
    "    candidates = []\n",
    "    # 제목/굵은글/정의형 문장 등에서 후보 수집(간단 규칙)\n",
    "    candidates.append(title)\n",
    "    for m in re.finditer(r\"\\*\\*(.+?)\\*\\*\", body):\n",
    "        candidates.append(m.group(1))\n",
    "    for m in re.finditer(r\"(.+?)(?:란|은|는)\\s.+?(?:이다|입니다)\\.\", body):\n",
    "        if len(m.group(1)) <= 40:\n",
    "            candidates.append(m.group(1))\n",
    "    # 정규화 + dedup\n",
    "    norm = []\n",
    "    seen = set()\n",
    "    for c in candidates:\n",
    "        k = normalize_key(c)\n",
    "        if k and k not in seen:\n",
    "            seen.add(k); norm.append(k)\n",
    "    return norm[:100]\n",
    "\n",
    "# --------- 마크다운 파서(간단): H1~H3 섹션/코드/표/이미지 ---------\n",
    "CODE_BLOCK_RE = re.compile(r\"```([a-zA-Z0-9_-]*)[^\\n]*\\n(.*?)```\", re.DOTALL)\n",
    "TABLE_RE = re.compile(r\"(?:^\\|.*\\|\\s*\\n)+\", re.MULTILINE)  # Markdown 표 블록 대략 매칭\n",
    "IMAGE_RE = re.compile(r\"!\\[(.*?)\\]\\((.*?)(?:\\s+\\\"(.*?)\\\")?\\)\")\n",
    "\n",
    "@dataclass\n",
    "class Tile:\n",
    "    id: str\n",
    "    type: str  # definition|explanation|code|table|image\n",
    "    text: str\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class SectionPack:\n",
    "    id: str\n",
    "    title: str\n",
    "    heading_path: str\n",
    "    text: str               # 섹션 전체 텍스트(코드/표 캡션 요약 포함)\n",
    "    tiles: List[Tile]\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "def split_markdown_to_sections_hierarchical(md_text: str, doc_id: str) -> List[SectionPack]:\n",
    "    \"\"\"\n",
    "    계층구조를 보존하는 마크다운 분할 함수\n",
    "    \n",
    "    H2/H3 기준 섹션을 만들고, 섹션별로 타일(정의/설명/코드/표/이미지)을 생성.\n",
    "    코드/표는 '원자' 보존: 절대로 분할하지 않음.\n",
    "    계층구조를 보존하여 title에 전체 경로를 포함합니다.\n",
    "    \"\"\"\n",
    "    # 헤더 파싱: 모든 헤더(H1~H6) 라인 인덱스 수집\n",
    "    lines = md_text.splitlines()\n",
    "    header_idxs: List[Tuple[int, str, int]] = []  # (line_idx, title, level)\n",
    "    for i, ln in enumerate(lines):\n",
    "        m = re.match(r\"^(#{1,6})\\s+(.*)\", ln)  # H1~H6 모두 포함\n",
    "        if m:\n",
    "            level = len(m.group(1))\n",
    "            header_idxs.append((i, m.group(2).strip(), level))\n",
    "\n",
    "    # 계층구조를 보존하여 경로 생성\n",
    "    current_hierarchy: List[str] = []  # 현재까지의 계층 구조\n",
    "    hierarchical_headers: List[Tuple[int, str, int, str]] = []  # (line_idx, title, level, full_path)\n",
    "    \n",
    "    for line_idx, title, level in header_idxs:\n",
    "        # 계층 구조 업데이트\n",
    "        if level == 1:\n",
    "            current_hierarchy = [title]\n",
    "        elif level <= len(current_hierarchy):\n",
    "            current_hierarchy = current_hierarchy[:level-1] + [title]\n",
    "        else:\n",
    "            current_hierarchy.append(title)\n",
    "        \n",
    "        # 전체 경로 생성\n",
    "        full_path = ' > '.join(current_hierarchy)\n",
    "        hierarchical_headers.append((line_idx, title, level, full_path))\n",
    "\n",
    "    # H2/H3 기준으로 섹션 경계 설정 (계층구조 정보 포함)\n",
    "    h2h3_headers = [(idx, title, level, path) for idx, title, level, path in hierarchical_headers \n",
    "                    if level in [2, 3]]\n",
    "    \n",
    "    boundaries = []\n",
    "    for idx, (line_idx, title, level, full_path) in enumerate(h2h3_headers):\n",
    "        start = line_idx\n",
    "        end = h2h3_headers[idx+1][0] if idx+1 < len(h2h3_headers) else len(lines)\n",
    "        boundaries.append((start, end, title, level, full_path))\n",
    "\n",
    "    section_packs: List[SectionPack] = []\n",
    "\n",
    "    for start, end, title, level, full_path in boundaries:\n",
    "        raw = \"\\n\".join(lines[start:end])\n",
    "        section_id = str(uuid.uuid4())\n",
    "\n",
    "        # 코드블록 추출(원문 보존)\n",
    "        code_tiles = []\n",
    "        def code_repl(m):\n",
    "            lang = (m.group(1) or \"\").lower()\n",
    "            code = m.group(2)\n",
    "            tile = Tile(\n",
    "                id=str(uuid.uuid4()),\n",
    "                type=\"code\",\n",
    "                text=code.strip(),\n",
    "                metadata={\"code_lang\": lang or \"text\"}\n",
    "            )\n",
    "            code_tiles.append(tile)\n",
    "            return f\"\\n[CODE_BLOCK::{tile.id}]\\n\"  # 자리표시자\n",
    "\n",
    "        raw_wo_code = re.sub(CODE_BLOCK_RE, code_repl, raw, flags=re.DOTALL)\n",
    "\n",
    "        # 표 추출(원문 보존)\n",
    "        table_tiles = []\n",
    "        def table_repl(m):\n",
    "            tbl = m.group(0)\n",
    "            tile = Tile(\n",
    "                id=str(uuid.uuid4()),\n",
    "                type=\"table\",\n",
    "                text=tbl.strip(),\n",
    "                metadata={}\n",
    "            )\n",
    "            table_tiles.append(tile)\n",
    "            return f\"\\n[TABLE_BLOCK::{tile.id}]\\n\"\n",
    "\n",
    "        raw_wo_code_table = re.sub(TABLE_RE, table_repl, raw_wo_code, flags=re.MULTILINE)\n",
    "\n",
    "        # 이미지 캡션 추출\n",
    "        image_tiles = []\n",
    "        def image_repl(m):\n",
    "            alt, path, title_opt = m.group(1), m.group(2), m.group(3) or \"\"\n",
    "            caption = (alt or title_opt or path)\n",
    "            tile = Tile(\n",
    "                id=str(uuid.uuid4()),\n",
    "                type=\"image\",\n",
    "                text=caption.strip(),\n",
    "                metadata={\"image_path\": path}\n",
    "            )\n",
    "            image_tiles.append(tile)\n",
    "            return f\"\\n[IMAGE_BLOCK::{tile.id}]\\n\"\n",
    "\n",
    "        raw_clean = re.sub(IMAGE_RE, image_repl, raw_wo_code_table)\n",
    "\n",
    "        # 정의/설명 타일 만들기\n",
    "        # 첫 단락을 definition, 나머지를 explanation 타일들로 (문단 기준 분할, 10~15% 겹침 없음)\n",
    "        paragraphs = [p.strip() for p in re.split(r\"\\n\\s*\\n\", raw_clean) if p.strip()]\n",
    "        tiles: List[Tile] = []\n",
    "\n",
    "        if paragraphs:\n",
    "            tiles.append(Tile(\n",
    "                id=str(uuid.uuid4()),\n",
    "                type=\"definition\",\n",
    "                text=paragraphs[0],\n",
    "                metadata={}\n",
    "            ))\n",
    "            for p in paragraphs[1:]:\n",
    "                tiles.append(Tile(\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    type=\"explanation\",\n",
    "                    text=p,\n",
    "                    metadata={}\n",
    "                ))\n",
    "\n",
    "        # 코드/표/이미지 타일 추가 (원자 보존)\n",
    "        tiles.extend(code_tiles)\n",
    "        tiles.extend(table_tiles)\n",
    "        tiles.extend(image_tiles)\n",
    "\n",
    "        # 메타데이터 구성\n",
    "        heading_path = full_path  # 계층구조 전체 경로 사용\n",
    "        body_for_keys = \"\\n\".join(t.text for t in tiles if t.type in (\"definition\",\"explanation\"))\n",
    "        term_keys = extract_term_keys(title, body_for_keys)\n",
    "        exact_keys = extract_exact_keys(raw)\n",
    "\n",
    "        # 섹션팩 텍스트(LLM 주입용): 자리표시자 → 간단 요약문으로 치환\n",
    "        def restore_placeholders(s: str) -> str:\n",
    "            s = re.sub(r\"\\[CODE_BLOCK::([-\\w]+)\\]\", \"[코드블록: 전체 포함]\", s)\n",
    "            s = re.sub(r\"\\[TABLE_BLOCK::([-\\w]+)\\]\", \"[표: 전체 포함]\", s)\n",
    "            s = re.sub(r\"\\[IMAGE_BLOCK::([-\\w]+)\\]\", \"[이미지 캡션 포함]\", s)\n",
    "            return s\n",
    "\n",
    "        section_text = restore_placeholders(raw_clean)\n",
    "\n",
    "        pack = SectionPack(\n",
    "            id=section_id,\n",
    "            title=full_path,  # 계층구조 전체 경로를 title로 사용\n",
    "            heading_path=heading_path,\n",
    "            text=section_text.strip(),\n",
    "            tiles=tiles,\n",
    "            metadata={\n",
    "                \"doc_id\": doc_id,\n",
    "                \"section_title\": title,  # 원래 제목\n",
    "                \"heading_path\": heading_path,  # 전체 경로\n",
    "                \"term_keys\": term_keys,\n",
    "                \"exact_keys\": exact_keys,\n",
    "            }\n",
    "        )\n",
    "        # 타일 공통 메타 바인딩\n",
    "        for t in pack.tiles:\n",
    "            t.metadata.update({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"section_id\": section_id,\n",
    "                \"section_title\": title,  # 원래 제목\n",
    "                \"heading_path\": heading_path,  # 전체 경로\n",
    "            })\n",
    "            if t.type == \"table\":\n",
    "                # 표 헤더/키 후보 추출(간단): 1행을 헤더로 가정\n",
    "                lines_tbl = [ln for ln in t.text.splitlines() if ln.strip()]\n",
    "                if lines_tbl:\n",
    "                    t.metadata[\"table_header\"] = lines_tbl[0]\n",
    "            if t.type == \"code\":\n",
    "                t.metadata[\"exact_keys\"] = extract_exact_keys(t.text)\n",
    "\n",
    "        section_packs.append(pack)\n",
    "\n",
    "    return section_packs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bacd4bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot process flags argument with a compiled pattern",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m all_text = read_file_content(\u001b[33m\"\u001b[39m\u001b[33mdata/dev_center_guide_allmd_touched.md\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# print(all_text)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m list_section = \u001b[43msplit_markdown_to_sections_hierarchical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miap_dev_integration_guide\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m cnt = \u001b[32m0\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m list_section:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36msplit_markdown_to_sections_hierarchical\u001b[39m\u001b[34m(md_text, doc_id)\u001b[39m\n\u001b[32m    138\u001b[39m     code_tiles.append(tile)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[CODE_BLOCK::\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtile.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 자리표시자\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m raw_wo_code = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCODE_BLOCK_RE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_repl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOTALL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# 표 추출(원문 보존)\u001b[39;00m\n\u001b[32m    144\u001b[39m table_tiles = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/re/__init__.py:185\u001b[39m, in \u001b[36msub\u001b[39m\u001b[34m(pattern, repl, string, count, flags)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msub\u001b[39m(pattern, repl, string, count=\u001b[32m0\u001b[39m, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    179\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m.sub(repl, string, count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/re/__init__.py:282\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(pattern, flags)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pattern, Pattern):\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcannot process flags argument with a compiled pattern\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pattern\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _compiler.isstring(pattern):\n",
      "\u001b[31mValueError\u001b[39m: cannot process flags argument with a compiled pattern"
     ]
    }
   ],
   "source": [
    "### TEST_CODE ###\n",
    "\n",
    "def read_file_content(input_path: str) -> str:\n",
    "    try:\n",
    "        # UTF-8 인코딩으로 파일 읽기\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {input_path}\")\n",
    "          \n",
    "all_text = read_file_content(\"data/dev_center_guide_allmd_touched.md\") \n",
    "# print(all_text)\n",
    "\n",
    "list_section = split_markdown_to_sections_hierarchical(all_text, doc_id=\"iap_dev_integration_guide\")\n",
    "\n",
    "cnt = 0\n",
    "for section in list_section:\n",
    "    print(section)\n",
    "    cnt += 1\n",
    "    # if 'CANCELED' in section.text:\n",
    "    #     print(section.title)\n",
    "    #     print(\"=\" * 50)\n",
    "    #     print(section.text)\n",
    "    #     print(\"-\" * 100)\n",
    "    #     cnt += 1\n",
    "\n",
    "print(f\"문장 개수: {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36b08c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "def build_retrievers_from_md(md_path: str, doc_id: str):\n",
    "    md = Path(md_path).read_text(encoding=\"utf-8\")\n",
    "    packs = split_markdown_to_sections(md, doc_id=doc_id)\n",
    "\n",
    "    child_docs: List[Document] = []\n",
    "    for pack in packs:\n",
    "        for t in pack.tiles:\n",
    "            meta = dict(t.metadata)\n",
    "            term_keys = \" \".join(pack.metadata.get(\"term_keys\", []))\n",
    "            exact_keys = \" \".join(pack.metadata.get(\"exact_keys\", []))\n",
    "            if t.type == \"code\":\n",
    "                exact_keys += \" \" + \" \".join(t.metadata.get(\"exact_keys\", []))\n",
    "            meta[\"term_keys\"] = term_keys\n",
    "            meta[\"exact_keys\"] = exact_keys\n",
    "            meta[\"tile_type\"] = t.type\n",
    "            child_docs.append(Document(page_content=t.text, metadata=meta))\n",
    "\n",
    "    # --- 임베딩: Ollama bge-m3 ---\n",
    "    emb = OllamaEmbeddings(model=\"bge-m3:latest\")  # GPU/CPU 자동 판단\n",
    "\n",
    "    child_vectorstore = FAISS.from_documents(\n",
    "        child_docs, emb, distance_strategy=DistanceStrategy.COSINE\n",
    "    )\n",
    "\n",
    "    # --- BM25 (정확일치 강화: term_keys/exact_keys 포함) ---\n",
    "    bm25_docs = []\n",
    "    for d in child_docs:\n",
    "        extra = f\"\\n{d.metadata.get('term_keys','')}\\n{d.metadata.get('exact_keys','')}\"\n",
    "        bm25_docs.append(Document(page_content=d.page_content + extra, metadata=d.metadata))\n",
    "    bm25 = BM25Retriever.from_documents(bm25_docs); bm25.k = 12\n",
    "\n",
    "    vector_retriever = child_vectorstore.as_retriever(search_kwargs={\"k\": 12})\n",
    "    ensemble = EnsembleRetriever(retrievers=[bm25, vector_retriever], weights=[0.55, 0.45])\n",
    "\n",
    "    # --- Parent Join 준비 ---\n",
    "    parent_store = InMemoryStore()\n",
    "    parent_docs = []\n",
    "    for p in packs:\n",
    "        parent_docs.append(Document(\n",
    "            page_content=p.text,\n",
    "            metadata=p.metadata | {\"section_id\": p.id, \"section_title\": p.title}\n",
    "        ))\n",
    "    for d in parent_docs:\n",
    "        parent_store.mset([(d.metadata[\"section_id\"], d)])\n",
    "\n",
    "    child_store = InMemoryStore()\n",
    "    for d in child_docs:\n",
    "        child_store.mset([(d.metadata[\"section_id\"], d)])\n",
    "        # child_store.madd([(d.metadata[\"section_id\"], d)])\n",
    "\n",
    "    return packs, ensemble, parent_store, child_vectorstore\n",
    "\n",
    "def hybrid_parent_search(query: str, ensemble: EnsembleRetriever, parent_store: InMemoryStore, k: int = 4) -> List[Document]:\n",
    "    child_hits = ensemble.get_relevant_documents(query)\n",
    "    bucket_by_section = {}\n",
    "    for ch in child_hits:\n",
    "        sid = ch.metadata.get(\"section_id\")\n",
    "        bucket_by_section.setdefault(sid, []).append(ch)\n",
    "    ordered_sections = list(bucket_by_section.keys())[:k]\n",
    "    parent_results = []\n",
    "    for sid in ordered_sections:\n",
    "        doc = parent_store.mget([sid])[0]\n",
    "        parent_results.append(doc)\n",
    "    return parent_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39218cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "785f87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "def build_llm():\n",
    "    # 필요 시 num_ctx(컨텍스트 길이)나 num_predict(출력 길이) 조정 가능\n",
    "    llm = ChatOllama(\n",
    "        model=\"exaone3.5:latest\",\n",
    "        temperature=0,\n",
    "        # num_ctx=8192,   # 모델/로컬 자원에 맞게 조절\n",
    "        # num_predict=1024\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def answer(query: str, ensemble: EnsembleRetriever, parent_store: InMemoryStore, llm: ChatOllama, k: int = 4) -> str:\n",
    "    parents = hybrid_parent_search(query, ensemble, parent_store, k=k)\n",
    "    context_blocks = []\n",
    "    for i, p in enumerate(parents, 1):\n",
    "        context_blocks.append(f\"[Section {i}: {p.metadata.get('heading_path')}]\\\\n{p.page_content}\")\n",
    "\n",
    "    system = SystemMessage(content=(\n",
    "        \"당신은 기술 문서 기반 QA 어시스턴트입니다. \"\n",
    "        \"반드시 제공된 컨텍스트만으로 답하고, 불확실하면 명시하세요.\"\n",
    "    ))\n",
    "    user = HumanMessage(content=(\n",
    "        f\"질문: {query}\\n\\n컨텍스트:\\n\" + \"\\n\\n\".join(context_blocks)\n",
    "    ))\n",
    "    res = llm([system, user])\n",
    "    return res.content\n",
    "\n",
    "# =============== 실행 예시 ===============\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 샘플 마크다운 파일 경로\n",
    "#     md_path = \"pns_sample.md\"   # 제공하신 PNS 예제를 저장한 파일\n",
    "#     packs, ensemble, parent_store, child_vectorstore = build_retrievers_from_md(md_path, doc_id=\"pns_doc_v1\")\n",
    "#     llm = build_llm()\n",
    "\n",
    "#     q1 = \"PNS 3.1.0에서 packageName이 clientId로 바뀐 이유와 주의사항을 알려줘\"\n",
    "#     q2 = \"paymentMethod의 종류와 설명 전체를 보여줘\"\n",
    "#     q3 = \"messageType이 SINGLE_PAYMENT_TRANSACTION일 때 JSON 필드 목록\"\n",
    "\n",
    "#     print(\"Q1:\", answer(q1, ensemble, parent_store, llm))\n",
    "#     print(\"Q2:\", answer(q2, ensemble, parent_store, llm))\n",
    "#     print(\"Q3:\", answer(q3, ensemble, parent_store, llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6077e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 PNS는 **Payment Notification Service**의 약자로, 모바일 네트워크 연결의 불안정성을 보완하기 위해 개발사가 지정한 서버로 원스토어가 사용자의 결제 상태 (결제 완료, 결제 취소 등) 정보를 메시지 형태로 전송하는 기능입니다. 이를 통해 결제 트랜잭션의 상태를 안정적으로 전달하고 관리할 수 있습니다.\n",
      "Q2: 제공된 컨텍스트에서 PNS (아마도 원스토어 인앱 결제 시스템을 가리키는 것으로 추정됨)의 `purchaseState`에 대한 구체적인 값 목록은 명시적으로 언급되어 있지 않습니다. 주어진 정보는 주로 인앱 상품의 유형 (관리형 상품, 구독형 상품 등)과 관련된 파라미터 및 메서드에 초점을 맞추고 있습니다.\n",
      "\n",
      "`purchaseState`에 대한 일반적인 인앱 결제 시스템의 값들은 다음과 같을 수 있지만, 이는 특정 컨텍스트나 문서에 따라 다를 수 있습니다:\n",
      "\n",
      "- **PENDING**: 구매 요청이 아직 처리 중인 상태\n",
      "- **COMPLETED**: 구매가 성공적으로 완료된 상태\n",
      "- **REFUNDED**: 환불이 이루어진 상태\n",
      "- **FAILED**: 구매 과정에서 오류가 발생하여 실패한 상태\n",
      "\n",
      "하지만, 이 값들은 제공된 컨텍스트에서 직접적으로 확인된 것이 아니므로, 정확한 `purchaseState` 값들을 알고 싶으시다면 원스토어 인앱 결제 API 문서나 관련 SDK 문서를 직접 참조하시는 것이 가장 정확할 것입니다. 만약 추가 정보가 필요하시다면, 해당 문서나 공식 지원 채널을 통해 확인하시는 것을 권장드립니다.\n",
      "Q3: Push Notification과 Payment Notification의 주요 차이점은 다음과 같습니다:\n",
      "\n",
      "1. **목적**:\n",
      "   - **Push Notification**: 주로 사용자에게 실시간으로 정보를 전달하는 데 사용됩니다. 이는 앱 내에서 사용자에게 새로운 업데이트, 메시지, 이벤트 알림 등을 즉시 알리는 데 초점을 맞춥니다. 예를 들어, 새로운 콘텐츠 알림, 친구 요청, 중요한 앱 이벤트 등이 여기에 해당합니다.\n",
      "   - **Payment Notification**: 주로 결제 트랜잭션의 상태 업데이트를 위한 것입니다. 사용자의 결제 활동 (결제 완료, 결제 취소 등)에 대한 정보를 개발사의 서버로 전송하여 결제 상태를 실시간으로 관리하고 업데이트하는 데 사용됩니다.\n",
      "\n",
      "2. **사용 컨텍스트**:\n",
      "   - **Push Notification**: 사용자 경험 향상을 위해 앱 외부에서 사용자에게 직접 알림을 보내는 데 사용됩니다. 사용자가 앱을 실행하지 않아도 알림을 받을 수 있습니다.\n",
      "   - **Payment Notification**: 주로 백엔드 시스템 간의 통신으로, 원스토어의 결제 시스템에서 개발사의 서버로 결제 상태 변경 정보를 전달합니다. 이는 주로 서버 간 데이터 동기화와 결제 트랜잭션 관리에 활용됩니다.\n",
      "\n",
      "3. **데이터 내용**:\n",
      "   - **Push Notification**: 다양한 유형의 사용자 관련 정보나 앱 내 이벤트를 포함할 수 있습니다.\n",
      "   - **Payment Notification**: 주로 결제 관련 정보를 포함합니다. 예를 들어, 결제 ID, 결제 상태 (성공, 실패, 취소 등), 결제 방법, 사용자 정보 등이 포함될 수 있습니다.\n",
      "\n",
      "요약하자면, Push Notification은 사용자에게 직접적인 정보 전달에 초점을 맞추고, Payment Notification은 결제 트랜잭션의 정확한 상태 관리와 업데이트에 중점을 두고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 샘플 마크다운 파일 경로\n",
    "md_path = \"data/dev_center_guide_allmd_touched.md\"   # 제공하신 PNS 예제를 저장한 파일\n",
    "packs, ensemble, parent_store, child_vectorstore = build_retrievers_from_md(md_path, doc_id=\"pns_doc_v1\")\n",
    "llm = build_llm()\n",
    "\n",
    "q1 = \"PNS는 무엇입니까?\"\n",
    "q2 = \"PNS의 메세지의 purchaseState는 어떤 값들이 있습니까?\"\n",
    "q3 = \"Push Notification과 Payment Notification의 차이는 무엇입니까?\"\n",
    "\n",
    "print(\"Q1\", answer(q1, ensemble, parent_store, llm))\n",
    "print(\"Q2:\", answer(q2, ensemble, parent_store, llm))\n",
    "print(\"Q3:\", answer(q3, ensemble, parent_store, llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37f12f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
