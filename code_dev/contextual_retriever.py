"""
Contextual Retrieval Class Implementation

ì´ ëª¨ë“ˆì€ ë¬¸ì„œì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ìƒì„±í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” 
ContextualRetriever í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
from pathlib import Path
from typing import Optional, List
from langchain.docstore.document import Document
from langchain_ollama import ChatOllama
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser


class ContextualRetriever:
    """Contextual Retrievalì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, whole_document: str, model_name: str = "exaone3.5:latest", temperature: float = 0.1):
        """
        ContextualRetriever ì´ˆê¸°í™”
        
        Args:
            whole_document (str): ì „ì²´ ë¬¸ì„œ ë‚´ìš©
            model_name (str): ì‚¬ìš©í•  LLM ëª¨ë¸ëª… (ê¸°ë³¸ê°’: "exaone3.5:latest")
            temperature (float): LLM temperature ì„¤ì • (ê¸°ë³¸ê°’: 0.1)
        """
        self.whole_document = whole_document
        self.model_name = model_name
        self.temperature = temperature
        
        # LLM ì´ˆê¸°í™”
        self._initialize_llm()
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        self._setup_prompt()
        
        # ì²´ì¸ êµ¬ì„±
        self._setup_chain()
        
        print(f"ğŸš€ ContextualRetriever ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“„ ì „ì²´ ë¬¸ì„œ ê¸¸ì´: {len(self.whole_document):,} characters")
        print(f"ğŸ¤– ëª¨ë¸: {self.model_name}")
        print(f"ğŸŒ¡ï¸ Temperature: {self.temperature}")
        
    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        print(f"ğŸ¤– LLM ì´ˆê¸°í™” ì¤‘... ({self.model_name})")
        self.llm = ChatOllama(
            model=self.model_name,
            temperature=self.temperature
        )
        
    def _setup_prompt(self):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •"""
        print("ğŸ“ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • ì¤‘...")
        self.contextual_prompt = PromptTemplate.from_template(
            """<document> 
{WHOLE_DOCUMENT} 
</document> 
ë‹¤ìŒì€ chunk ì²˜ë¦¬ëœ Documentì…ë‹ˆë‹¤. chunkì˜ ë‚´ìš©ì€ ì „ì²´ ë¬¸ì„œì—ì„œ ì¼ë¶€ë¶„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
<chunk> 
{CHUNK_CONTENT}
</chunk> 
- documentì˜ ë§¥ë½ì—ì„œ chunkë¥¼ ê°„ë‹¨ ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
- ìš”ì•½ë¬¸ì˜ ìµœëŒ€ í† í°ì€ 150 ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. 
- ìš”ì•½ë¬¸ì˜ ëª©ì ì€ Document ë‚´ì— ì¬ì‚½ì…í•˜ì—¬ retrieverë¥¼ í†µí•© ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
- ìš”ì•½ë¬¸ì€ í•œê¸€ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë‹¨, chunkë‚´ì— ì½”ë“œëª…, ì˜ë¬¸ ì´ë‹ˆì…œ í˜¹ì€ ì˜ì–´ í‘œí˜„ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ”ë° ë°˜ë“œì‹œ í•„ìš”í•œ ë‚´ìš©ì´ë¼ë©´ ì˜ì–´ ê·¸ëŒ€ë¡œ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìš”ì•½ë¬¸ì„ ëŒ€í‘œí•  ìˆ˜ ìˆëŠ” ìš©ì–´(ì˜ˆ, ì˜ë¬¸ ì´ë‹ˆì…œ, ê¸°ëŠ¥ëª… ë“±)ëŠ” ìš”ì•½ë¬¸ ë‚´ì— í¬í•¨í•´ ì£¼ì„¸ìš”.
- ì£¼ìš” ì½”ë“œê°’ì€ í•œêµ­ì–´ë¡œ ë³€í™˜í•˜ì§€ ë§ˆì„¸ìš”.
- ìš”ì•½ë¬¸ì˜ ëë¶€ë¶„ì— ë¬¸ì„œë¥¼ ëŒ€í‘œí•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.
"""
        )
        
    def _setup_chain(self):
        """ì²´ì¸ êµ¬ì„±"""
        print("â›“ï¸ ì²´ì¸ êµ¬ì„± ì¤‘...")
        self.chain = self.contextual_prompt | self.llm | StrOutputParser()
        
    def get_contextual_text(self, chunk_content: str, verbose: bool = True) -> Optional[Document]:
        """
        ì£¼ì–´ì§„ ì²­í¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ìƒì„±í•˜ê³  í–¥ìƒëœ Documentë¥¼ ë°˜í™˜
        
        Args:
            chunk_content (str): ì²˜ë¦¬í•  ì²­í¬ ë‚´ìš©
            verbose (bool): ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            Document: í–¥ìƒëœ Document ê°ì²´ (ì„±ê³µì‹œ) ë˜ëŠ” None (ì‹¤íŒ¨ì‹œ)
        """
        if verbose:
            print(f"\nğŸ” ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„± ì‹œì‘...")
            print(f"ğŸ“Š ì²­í¬ ê¸¸ì´: {len(chunk_content):,} characters")
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„±
            context = self.chain.invoke({
                "WHOLE_DOCUMENT": self.whole_document,
                "CHUNK_CONTENT": chunk_content
            })
            
            if verbose:
                print("=" * 50)
                print(f"âœ… ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸:\n{context}")
                print("=" * 50)
            
            # í–¥ìƒëœ Document ìƒì„±
            enhanced_content = f"[Abstract]: {context}\n\n[Origin]:{chunk_content}"
            
            enhanced_doc = Document(
                page_content=enhanced_content,
                metadata={
                    "original_content": chunk_content,
                    "contextual_info": context,
                    "source": "contextual_retrieval",
                    "model": self.model_name,
                    "original_length": len(chunk_content),
                    "enhanced_length": len(enhanced_content)
                }
            )
            
            if verbose:
                print(f"âœ… í–¥ìƒëœ Document ìƒì„± ì™„ë£Œ!")
                print(f"ğŸ“ ì›ë³¸ ê¸¸ì´: {len(chunk_content):,} characters")
                print(f"ğŸ“ í–¥ìƒëœ ê¸¸ì´: {len(enhanced_doc.page_content):,} characters")
                print(f"ğŸ“ˆ ì¦ê°€ìœ¨: {(len(enhanced_doc.page_content) / len(chunk_content) - 1) * 100:.1f}%")
            
            return enhanced_doc
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def process_multiple_chunks(self, chunks: list, verbose: bool = False) -> list:
        """
        ì—¬ëŸ¬ ì²­í¬ë¥¼ ì¼ê´„ ì²˜ë¦¬
        
        Args:
            chunks (list): ì²˜ë¦¬í•  ì²­í¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            verbose (bool): ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            list: í–¥ìƒëœ Document ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ”„ {len(chunks)}ê°œ ì²­í¬ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘...")
        
        enhanced_docs = []
        for i, chunk in enumerate(chunks, 1):
            print(f"\n[{i}/{len(chunks)}] ì²­í¬ ì²˜ë¦¬ ì¤‘...")
            enhanced_doc = self.get_contextual_text(chunk, verbose=verbose)
            if enhanced_doc:
                enhanced_docs.append(enhanced_doc)
            else:
                print(f"âš ï¸ ì²­í¬ {i} ì²˜ë¦¬ ì‹¤íŒ¨")
        
        print(f"\nâœ… ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ: {len(enhanced_docs)}/{len(chunks)} ì„±ê³µ")
        return enhanced_docs
    
    def preview_enhancement(self, chunk_content: str, max_chars: int = 500):
        """
        í–¥ìƒëœ Documentì˜ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì¶œë ¥
        
        Args:
            chunk_content (str): ì²˜ë¦¬í•  ì²­í¬ ë‚´ìš©
            max_chars (int): ë¯¸ë¦¬ë³´ê¸° ìµœëŒ€ ë¬¸ì ìˆ˜
        """
        enhanced_doc = self.get_contextual_text(chunk_content, verbose=False)
        if enhanced_doc:
            print("\nğŸ“„ í–¥ìƒëœ Document ë¯¸ë¦¬ë³´ê¸°:")
            print("-" * 60)
            preview_text = enhanced_doc.page_content[:max_chars]
            if len(enhanced_doc.page_content) > max_chars:
                preview_text += "..."
            print(preview_text)
            print("-" * 60)
        else:
            print("âŒ Document í–¥ìƒ ì‹¤íŒ¨")
    
    def get_stats(self) -> dict:
        """
        í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ì˜ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜
        
        Returns:
            dict: í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "model_name": self.model_name,
            "temperature": self.temperature,
            "document_length": len(self.whole_document),
            "document_size_mb": len(self.whole_document) / (1024 * 1024),
        }
    
    def __repr__(self) -> str:
        """í´ë˜ìŠ¤ì˜ ë¬¸ìì—´ í‘œí˜„"""
        return f"ContextualRetriever(model='{self.model_name}', doc_size={len(self.whole_document):,} chars)"


def create_contextual_retriever(file_path: str, **kwargs) -> ContextualRetriever:
    """
    íŒŒì¼ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ ContextualRetriever ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        file_path (str): ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
        **kwargs: ContextualRetriever ìƒì„±ìì— ì „ë‹¬í•  ì¶”ê°€ ì¸ìˆ˜
        
    Returns:
        ContextualRetriever: ì´ˆê¸°í™”ëœ ContextualRetriever ì¸ìŠ¤í„´ìŠ¤
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            whole_document = file.read()
        
        print(f"ğŸ“ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
        print(f"ğŸ“„ ë¬¸ì„œ í¬ê¸°: {len(whole_document):,} characters")
        
        return ContextualRetriever(whole_document, **kwargs)
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        raise
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    # ëª¨ë“ˆì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œì˜ í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ContextualRetriever ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ
    test_document = """
    ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ê°€ì´ë“œ
    
    1. ê°œìš”
    ì›ìŠ¤í† ì–´ëŠ” ëª¨ë°”ì¼ ì•± ê°œë°œìë“¤ì„ ìœ„í•œ ê²°ì œ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.
    
    2. PNS (Payment Notification Service)
    PNSëŠ” ê²°ì œ ì•Œë¦¼ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
    """
    
    # í…ŒìŠ¤íŠ¸ ì²­í¬
    test_chunk = "PNSëŠ” Payment Notification Serviceì˜ ì•½ìë¡œ ê²°ì œ ì•Œë¦¼ì„ ì œê³µí•©ë‹ˆë‹¤."
    
    try:
        # ContextualRetriever ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        retriever = ContextualRetriever(test_document)
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        result = retriever.get_contextual_text(test_chunk, verbose=False)
        
        if result:
            print("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"ğŸ“Š í†µê³„: {retriever.get_stats()}")
        else:
            print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
