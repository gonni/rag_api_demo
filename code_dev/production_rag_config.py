"""
í”„ë¡œë•ì…˜ RAG ì‹œìŠ¤í…œ ì„¤ì •

ì‹¤í—˜ ê²°ê³¼:
- HybridScoring ì „ëµ: 80% ì •í™•ë„ ë‹¬ì„±
- PNS+purchaseState ë¬¸ì„œ 4/5ê°œ ê²€ìƒ‰ ì„±ê³µ
- MultiLevelSplitting + HybridScoring ì¡°í•©ì´ ìµœì 
"""

from dataclasses import dataclass
from typing import Dict, List, Optional, TYPE_CHECKING
import os

if TYPE_CHECKING:
    from optimal_rag_pipeline import OptimalRAGPipeline


@dataclass
class RAGConfig:
    """RAG ì‹œìŠ¤í…œ ì„¤ì •"""
    
    # ë¬¸ì„œ ë¶„í•  ì„¤ì •
    document_splitting: Dict = None  # type: ignore
    
    # ê²€ìƒ‰ ì„¤ì •
    retrieval: Dict = None  # type: ignore
    
    # ì„ë² ë”© ì„¤ì •
    embedding: Dict = None  # type: ignore
    
    # ì„±ëŠ¥ ì„¤ì •
    performance: Dict = None  # type: ignore
    
    def __post_init__(self):
        if self.document_splitting is None:
            self.document_splitting = {
                # ê³„ì¸µë³„ ìµœì  ì²­í¬ í¬ê¸° (ì‹¤í—˜ ê²€ì¦ë¨)
                "chunk_sizes": {
                    "major": 2000,   # H1 ë ˆë²¨ - í° ì»¨í…ìŠ¤íŠ¸
                    "medium": 1200,  # H2 ë ˆë²¨ - ê· í˜•
                    "minor": 800     # H3+ ë ˆë²¨ - ì„¸ë¶€ì‚¬í•­
                },
                
                # ì²­í¬ ì˜¤ë²„ë© (ì»¨í…ìŠ¤íŠ¸ ì—°ì†ì„±)
                "chunk_overlap": 200,
                
                # êµ¬ë¶„ì ìš°ì„ ìˆœìœ„
                "separators": ["\n\n", "\n", ". ", "? ", "! ", ", "],
                
                # í—¤ë” ë¶„í•  ì„¤ì •
                "headers_to_split": [
                    ("#", "Header 1"),
                    ("##", "Header 2"), 
                    ("###", "Header 3"),
                    ("####", "Header 4")
                ]
            }
        
        if self.retrieval is None:
            self.retrieval = {
                # HybridScoring ê°€ì¤‘ì¹˜ (ì‹¤í—˜ ìµœì ê°’)
                "scoring_weights": {
                    "vector_score": 0.25,      # Vector ìœ ì‚¬ë„
                    "bm25_score": 0.20,        # BM25 ì ìˆ˜
                    "keyword_score": 0.25,     # í‚¤ì›Œë“œ í•„í„°ë§
                    "metadata_score": 0.30     # ë©”íƒ€ë°ì´í„° (ê°€ì¥ ì¤‘ìš”!)
                },
                
                # ê²€ìƒ‰ í›„ë³´ ìˆ˜
                "candidate_counts": {
                    "vector_k": 25,
                    "bm25_k": 25,
                    "keyword_filter_k": 15
                },
                
                # ë©”íƒ€ë°ì´í„° ì ìˆ˜ ì„¤ì •
                "metadata_scoring": {
                    "pns_purchasestate_both": 5.0,  # ìµœìš°ì„ 
                    "pns_match": 2.0,
                    "purchasestate_match": 2.0,
                    "hierarchy_match": 0.8,
                    "quality_weight": 0.5,
                    "density_weight": 10.0
                },
                
                # ë ˆë²¨ë³„ ê°€ì¤‘ì¹˜
                "level_weights": {
                    "major": 0.8,   # H1
                    "medium": 1.0,  # H2
                    "minor": 1.2    # H3+ (ì„¸ë¶€ì‚¬í•­ ì„ í˜¸)
                }
            }
        
        if self.embedding is None:
            self.embedding = {
                # ìµœì  ì„ë² ë”© ëª¨ë¸
                "model_name": "bge-m3:latest",
                
                # Vector store ì„¤ì •
                "vector_store": {
                    "type": "FAISS",
                    "search_type": "mmr",
                    "search_params": {
                        "lambda_mult": 0.7,
                        "fetch_k": 50
                    }
                },
                
                # BM25 ì„¤ì •
                "bm25_params": {
                    "k1": 1.5,
                    "b": 0.75
                }
            }
        
        if self.performance is None:
            self.performance = {
                # ì„±ëŠ¥ ì„ê³„ê°’
                "success_thresholds": {
                    "relevance_score": 0.4,      # 40% ì´ìƒ
                    "both_docs_min": 2,          # PNS+purchaseState 2ê°œ ì´ìƒ
                    "total_docs_returned": 5     # ê¸°ë³¸ ë°˜í™˜ ë¬¸ì„œ ìˆ˜
                },
                
                # í’ˆì§ˆ ì§€í‘œ
                "quality_metrics": {
                    "min_content_length": 50,    # ìµœì†Œ ì½˜í…ì¸  ê¸¸ì´
                    "max_content_length": 2000,  # ìµœëŒ€ ì½˜í…ì¸  ê¸¸ì´
                    "min_keyword_density": 0.01  # ìµœì†Œ í‚¤ì›Œë“œ ë°€ë„
                },
                
                # ëª¨ë‹ˆí„°ë§ ì„¤ì •
                "monitoring": {
                    "log_queries": True,
                    "log_performance": True,
                    "alert_low_performance": True,
                    "performance_threshold": 0.3
                }
            }


class ProductionRAGSystem:
    """í”„ë¡œë•ì…˜ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: RAGConfig = None):  # type: ignore
        self.config = config or RAGConfig()
        self.pipeline = None
        
    def initialize(self, document_path: str):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        from optimal_rag_pipeline import OptimalRAGPipeline
        
        print("ğŸš€ í”„ë¡œë•ì…˜ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        
        # ì„¤ì • ê²€ì¦
        self._validate_config()
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        self.pipeline = OptimalRAGPipeline(  # type: ignore
            document_path=document_path,
            embedding_model=self.config.embedding["model_name"]
        )
        
        # ì„¤ì • ì ìš©
        self._apply_config_to_pipeline()
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        self.pipeline.setup()  # type: ignore
        
        print("âœ… í”„ë¡œë•ì…˜ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        return self
    
    def _validate_config(self):
        """ì„¤ì • ê²€ì¦"""
        required_models = ["bge-m3:latest"]
        
        # ëª¨ë¸ í™•ì¸ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Ollama ëª¨ë¸ ì¡´ì¬ í™•ì¸)
        model_name = self.config.embedding["model_name"]
        if model_name not in required_models:
            print(f"âš ï¸  ê¶Œì¥ ëª¨ë¸: {required_models}")
        
        print("âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    
    def _apply_config_to_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ì— ì„¤ì • ì ìš©"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” pipeline ê°ì²´ì— config ê°’ë“¤ì„ ì ìš©
        # í˜„ì¬ëŠ” ê¸°ë³¸ ì„¤ì •ì´ ì´ë¯¸ ìµœì í™”ë˜ì–´ ìˆìŒ
        pass
    
    def search(self, query: str, **kwargs) -> Dict:
        """í”„ë¡œë•ì…˜ ê²€ìƒ‰"""
        if not self.pipeline:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ê¸°ë³¸ ì„¤ì •ê°’ ì ìš©
        k = kwargs.get('k', self.config.performance["success_thresholds"]["total_docs_returned"])
        
        # ê²€ìƒ‰ ì‹¤í–‰
        result = self.pipeline.search(query, k=k)
        
        # ì„±ëŠ¥ í‰ê°€
        performance = self._evaluate_performance(result)
        result['production_performance'] = performance
        
        # ë¡œê¹… (ì„ íƒì )
        if self.config.performance["monitoring"]["log_queries"]:
            self._log_query(query, result)
        
        return result
    
    def _evaluate_performance(self, result: Dict) -> Dict:
        """ì„±ëŠ¥ í‰ê°€"""
        perf = result['performance']
        thresholds = self.config.performance["success_thresholds"]
        
        evaluation = {
            "meets_relevance_threshold": perf['relevance_score'] >= thresholds["relevance_score"],
            "meets_both_docs_threshold": perf['both_docs'] >= thresholds["both_docs_min"],
            "overall_success": (
                perf['relevance_score'] >= thresholds["relevance_score"] and
                perf['both_docs'] >= thresholds["both_docs_min"]
            ),
            "performance_grade": self._calculate_grade(perf['relevance_score'])
        }
        
        return evaluation
    
    def _calculate_grade(self, relevance_score: float) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        if relevance_score >= 0.8:
            return "A+ (ìš°ìˆ˜)"
        elif relevance_score >= 0.6:
            return "A (ì–‘í˜¸)"
        elif relevance_score >= 0.4:
            return "B (ë³´í†µ)"
        elif relevance_score >= 0.2:
            return "C (ë¯¸í¡)"
        else:
            return "D (ê°œì„ í•„ìš”)"
    
    def _log_query(self, query: str, result: Dict):
        """ì¿¼ë¦¬ ë¡œê¹…"""
        perf = result['performance']
        prod_perf = result['production_performance']
        
        log_entry = {
            "query": query,
            "relevance_score": perf['relevance_score'],
            "both_docs": perf['both_docs'],
            "success": prod_perf['overall_success'],
            "grade": prod_perf['performance_grade']
        }
        
        # ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë¡œê¹… ì‹œìŠ¤í…œì— ì „ì†¡
        print(f"ğŸ“ ë¡œê·¸: {log_entry}")
    
    def health_check(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        test_queries = [
            "PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
            "Payment Notification Service í…ŒìŠ¤íŠ¸"
        ]
        
        results = []
        for query in test_queries:
            try:
                result = self.search(query)
                results.append(result['production_performance']['overall_success'])
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results.append(False)
        
        success_rate = sum(results) / len(results)
        
        health_status = {
            "system_healthy": success_rate >= 0.5,
            "success_rate": success_rate,
            "test_results": results,
            "recommendation": "ì •ìƒ" if success_rate >= 0.5 else "ì ê²€ í•„ìš”"
        }
        
        return health_status


# í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì • ì˜ˆì‹œ
def create_production_config() -> RAGConfig:
    """í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì • ìƒì„±"""
    return RAGConfig(
        # ê³ ì„±ëŠ¥ ì„¤ì •
        document_splitting={
            "chunk_sizes": {"major": 2000, "medium": 1200, "minor": 800},
            "chunk_overlap": 200,
        },
        
        # ìµœì í™”ëœ ê²€ìƒ‰ ì„¤ì •
        retrieval={
            "scoring_weights": {
                "vector_score": 0.25,
                "bm25_score": 0.20, 
                "keyword_score": 0.25,
                "metadata_score": 0.30
            }
        },
        
        # í”„ë¡œë•ì…˜ ì„±ëŠ¥ ê¸°ì¤€
        performance={
            "success_thresholds": {
                "relevance_score": 0.5,  # ë” ì—„ê²©í•œ ê¸°ì¤€
                "both_docs_min": 3,      # ë” ë§ì€ ê´€ë ¨ ë¬¸ì„œ ìš”êµ¬
                "total_docs_returned": 5
            },
            "monitoring": {
                "log_queries": True,
                "log_performance": True,
                "alert_low_performance": True
            }
        }
    )


def main():
    """í”„ë¡œë•ì…˜ ì‹œìŠ¤í…œ ì‹¤í–‰ ì˜ˆì‹œ"""
    
    # í”„ë¡œë•ì…˜ ì„¤ì •
    config = create_production_config()
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag_system = ProductionRAGSystem(config)
    rag_system.initialize("data/dev_center_guide_allmd_touched.md")
    
    # ìƒíƒœ í™•ì¸
    health = rag_system.health_check()
    print(f"ğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ: {health}")
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    query = "PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?"
    result = rag_system.search(query)
    
    print(f"\nğŸ¯ ê²€ìƒ‰ ê²°ê³¼:")
    print(f"ì„±ëŠ¥ ë“±ê¸‰: {result['production_performance']['performance_grade']}")
    print(f"ëª©í‘œ ë‹¬ì„±: {'âœ…' if result['production_performance']['overall_success'] else 'âŒ'}")


if __name__ == "__main__":
    main()
