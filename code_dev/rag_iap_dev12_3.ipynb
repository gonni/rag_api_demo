{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Retriever ê²€ìƒ‰ í’ˆì§ˆ ê·¹ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ **PNS ì„¹ì…˜ ë‚´ purchaseState** ê²€ìƒ‰ì„ ìœ„í•œ ìµœì ì˜ Retriever íŒŒì´í”„ë¼ì¸ì„ ì°¾ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ¯ ëª©í‘œ\n",
        "- **\"PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\"** ì¿¼ë¦¬ ìµœì í™”\n",
        "- PNS ì„¹ì…˜ ë‚´ purchaseState ë¬¸ì„œê°€ ìƒìœ„ì— ê²€ìƒ‰ë˜ë„ë¡ ê°œì„ \n",
        "- ë‹¤ì–‘í•œ Retriever ì „ëµ ë¹„êµ ë° ì„±ëŠ¥ ì¸¡ì •\n",
        "- ìµœì ì˜ RAG íŒŒì´í”„ë¼ì¸ ë„ì¶œ\n",
        "\n",
        "## ğŸ“‹ í…ŒìŠ¤íŠ¸í•  ì „ëµë“¤\n",
        "1. **ê¸°ë³¸ Vector + BM25 Ensemble**\n",
        "2. **ê³„ì¸µì  ë©”íƒ€ë°ì´í„° í™œìš© Retriever**\n",
        "3. **ì»¨í…ìŠ¤íŠ¸ ê°•í™” + ë¦¬ë­í‚¹**\n",
        "4. **í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ Retriever**\n",
        "5. **Multi-Query + ì•™ìƒë¸”**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
        "project_root = os.path.abspath('..')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain.schema import BaseRetriever\n",
        "\n",
        "# ì¶”ê°€ retriever ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "try:\n",
        "    from langchain.retrievers import ContextualCompressionRetriever\n",
        "    from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ Some advanced retrievers not available\")\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ê°œì„ ëœ MultiLevelSplittingStrategy (ì¬ì‚¬ìš©)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… MultiLevelSplittingStrategy í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# ì´ì „ì— ê²€ì¦ëœ MultiLevelSplittingStrategy ì¬ì‚¬ìš©\n",
        "class MultiLevelSplittingStrategy:\n",
        "    \"\"\"ë‹¤ì¤‘ ë ˆë²¨ ë¶„í•  ì „ëµ - ê°œì„ ëœ ë²„ì „\"\"\"\n",
        "    \n",
        "    def __init__(self, document_path: str):\n",
        "        self.document_path = document_path\n",
        "        self.raw_text = self._load_document()\n",
        "        \n",
        "    def _load_document(self) -> str:\n",
        "        with open(self.document_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    \n",
        "    def split_documents(self) -> List[Document]:\n",
        "        \"\"\"ë‹¤ì¤‘ ë ˆë²¨ë¡œ ë¬¸ì„œ ë¶„í• \"\"\"\n",
        "        documents = []\n",
        "        \n",
        "        # í—¤ë” ê¸°ë°˜ ë¶„í• \n",
        "        header_splitter = MarkdownHeaderTextSplitter(\n",
        "            headers_to_split_on=[\n",
        "                (\"#\", \"Header 1\"),\n",
        "                (\"##\", \"Header 2\"),\n",
        "                (\"###\", \"Header 3\"),\n",
        "                (\"####\", \"Header 4\")\n",
        "            ]\n",
        "        )\n",
        "        header_docs = header_splitter.split_text(self.raw_text)\n",
        "        \n",
        "        # ê³„ì¸µë³„ë¡œ ë¬¸ì„œ ê·¸ë£¹í•‘ (ê°€ì¥ êµ¬ì²´ì ì¸ ë ˆë²¨ ê¸°ì¤€)\n",
        "        hierarchy_groups = self._group_by_hierarchy(header_docs)\n",
        "        \n",
        "        # ê° ë ˆë²¨ë³„ ë¬¸ì„œ ìƒì„±\n",
        "        for level, group_docs in hierarchy_groups.items():\n",
        "            level_docs = self._create_level_documents(group_docs, level)\n",
        "            documents.extend(level_docs)\n",
        "            \n",
        "        return documents\n",
        "    \n",
        "    def _group_by_hierarchy(self, header_docs: List[Document]) -> Dict[str, List[Document]]:\n",
        "        \"\"\"ê³„ì¸µë³„ë¡œ ë¬¸ì„œ ê·¸ë£¹í•‘ - ê°€ì¥ êµ¬ì²´ì ì¸ ë ˆë²¨ ê¸°ì¤€\"\"\"\n",
        "        groups = {\"major\": [], \"medium\": [], \"minor\": []}\n",
        "        \n",
        "        for doc in header_docs:\n",
        "            metadata = doc.metadata\n",
        "            has_h1 = \"Header 1\" in metadata and metadata.get(\"Header 1\", \"\").strip()\n",
        "            has_h2 = \"Header 2\" in metadata and metadata.get(\"Header 2\", \"\").strip()\n",
        "            has_h3 = \"Header 3\" in metadata and metadata.get(\"Header 3\", \"\").strip()\n",
        "            has_h4 = \"Header 4\" in metadata and metadata.get(\"Header 4\", \"\").strip()\n",
        "            \n",
        "            # ê°€ì¥ êµ¬ì²´ì ì¸ í—¤ë” ë ˆë²¨ë¡œ ë¶„ë¥˜\n",
        "            if has_h4:\n",
        "                groups[\"minor\"].append(doc)\n",
        "            elif has_h3:\n",
        "                groups[\"minor\"].append(doc)\n",
        "            elif has_h2:\n",
        "                groups[\"medium\"].append(doc)\n",
        "            elif has_h1:\n",
        "                groups[\"major\"].append(doc)\n",
        "            else:\n",
        "                groups[\"minor\"].append(doc)  # ê¸°ë³¸ê°’\n",
        "        \n",
        "        return groups\n",
        "    \n",
        "    def _create_level_documents(self, docs: List[Document], level: str) -> List[Document]:\n",
        "        \"\"\"ë ˆë²¨ë³„ ë¬¸ì„œ ìƒì„±\"\"\"\n",
        "        level_documents = []\n",
        "        chunk_sizes = {\"major\": 2000, \"medium\": 1200, \"minor\": 800}\n",
        "        chunk_size = chunk_sizes.get(level, 1000)\n",
        "        \n",
        "        for doc in docs:\n",
        "            title_hierarchy = self._build_title_hierarchy(doc.metadata)\n",
        "            enhanced_content = self._enhance_with_context(doc.page_content, title_hierarchy, level)\n",
        "            \n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size, chunk_overlap=200,\n",
        "                separators=[\"\\\\n\\\\n\", \"\\\\n\", \". \", \"? \", \"! \", \", \"]\n",
        "            )\n",
        "            chunks = text_splitter.split_text(enhanced_content)\n",
        "            \n",
        "            for i, chunk in enumerate(chunks):\n",
        "                metadata = doc.metadata.copy()\n",
        "                metadata.update({\n",
        "                    \"chunk_index\": i,\n",
        "                    \"hierarchy_level\": level,\n",
        "                    \"title_hierarchy\": title_hierarchy,\n",
        "                    \"source_strategy\": f\"multi_level_{level}\",\n",
        "                    \"chunk_size\": len(chunk),\n",
        "                    \"contains_pns\": self._check_pns_context(chunk, title_hierarchy),\n",
        "                    \"contains_purchasestate\": 'purchasestate' in chunk.lower(),\n",
        "                    \"pns_purchasestate_both\": self._check_pns_context(chunk, title_hierarchy) and 'purchasestate' in chunk.lower()\n",
        "                })\n",
        "                level_documents.append(Document(page_content=chunk, metadata=metadata))\n",
        "        \n",
        "        return level_documents\n",
        "    \n",
        "    def _build_title_hierarchy(self, metadata: Dict) -> str:\n",
        "        \"\"\"ì œëª© ê³„ì¸µ êµ¬ì¡° ìƒì„±\"\"\"\n",
        "        hierarchy_parts = []\n",
        "        for level in range(1, 5):\n",
        "            header_key = f\"Header {level}\"\n",
        "            if header_key in metadata and metadata[header_key]:\n",
        "                hierarchy_parts.append(metadata[header_key].strip())\n",
        "        return \" > \".join(hierarchy_parts) if hierarchy_parts else \"Unknown\"\n",
        "    \n",
        "    def _enhance_with_context(self, content: str, title_hierarchy: str, level: str) -> str:\n",
        "        \"\"\"ë ˆë²¨ë³„ ì»¨í…ìŠ¤íŠ¸ ê°•í™”\"\"\"\n",
        "        is_pns_section = \"PNS\" in title_hierarchy.upper() or \"PAYMENT NOTIFICATION\" in title_hierarchy.upper()\n",
        "        \n",
        "        context_info = f\"[ê³„ì¸µ]: {title_hierarchy}\\\\n\"\n",
        "        if is_pns_section:\n",
        "            context_info += \"[PNS ê´€ë ¨]: ì´ ë‚´ìš©ì€ PNS(Payment Notification Service) ê²°ì œì•Œë¦¼ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ë©ë‹ˆë‹¤.\\\\n\"\n",
        "        context_info += f\"[ë ˆë²¨]: {level}\\\\n\\\\n\"\n",
        "        \n",
        "        return context_info + content\n",
        "    \n",
        "    def _check_pns_context(self, content: str, title_hierarchy: str) -> bool:\n",
        "        \"\"\"PNS ì»¨í…ìŠ¤íŠ¸ ì—¬ë¶€ í™•ì¸\"\"\"\n",
        "        content_upper = content.upper()\n",
        "        hierarchy_upper = title_hierarchy.upper()\n",
        "        return (\"PNS\" in hierarchy_upper or \"PAYMENT NOTIFICATION\" in hierarchy_upper or\n",
        "                \"PNS\" in content_upper or \"PAYMENT NOTIFICATION\" in content_upper)\n",
        "\n",
        "print(\"âœ… MultiLevelSplittingStrategy í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ê³ ê¸‰ Retriever í´ë˜ìŠ¤ë“¤ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ê³ ê¸‰ Retriever í´ë˜ìŠ¤ë“¤ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class RetrievalResult:\n",
        "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ìš© ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
        "    strategy_name: str\n",
        "    query: str\n",
        "    documents: List[Document]\n",
        "    scores: List[float]\n",
        "    pns_count: int\n",
        "    purchasestate_count: int\n",
        "    both_count: int\n",
        "    top3_relevance: float\n",
        "    precision_at_5: float\n",
        "\n",
        "class MetadataAwareRetriever:\n",
        "    \"\"\"ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ Retriever\"\"\"\n",
        "    \n",
        "    def __init__(self, documents: List[Document], embedding_model: str = \"bge-m3:latest\"):\n",
        "        self.documents = documents\n",
        "        self.embedding_model = embedding_model\n",
        "        self.vector_store = None\n",
        "        self.bm25_retriever = None\n",
        "        \n",
        "    def build_retrievers(self):\n",
        "        \"\"\"ê²€ìƒ‰ê¸° êµ¬ì¶•\"\"\"\n",
        "        print(\"ğŸ”§ MetadataAware ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\")\n",
        "        \n",
        "        # Vector store êµ¬ì¶•\n",
        "        embeddings = OllamaEmbeddings(model=self.embedding_model)\n",
        "        self.vector_store = FAISS.from_documents(self.documents, embeddings)\n",
        "        \n",
        "        # BM25 ê²€ìƒ‰ê¸° êµ¬ì¶•\n",
        "        self.bm25_retriever = BM25Retriever.from_documents(self.documents)\n",
        "        self.bm25_retriever.k = 20\n",
        "        \n",
        "        print(\"âœ… MetadataAware ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\")\n",
        "    \n",
        "    def retrieve(self, query: str, k: int = 10) -> List[Document]:\n",
        "        \"\"\"ë©”íƒ€ë°ì´í„° ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ê²€ìƒ‰\"\"\"\n",
        "        # 1. Vector ê²€ìƒ‰\n",
        "        vector_results = self.vector_store.similarity_search_with_score(query, k=20)\n",
        "        \n",
        "        # 2. BM25 ê²€ìƒ‰  \n",
        "        bm25_results = self.bm25_retriever.get_relevant_documents(query)[:20]\n",
        "        \n",
        "        # 3. ê²°ê³¼ í†µí•© ë° ë©”íƒ€ë°ì´í„° ìŠ¤ì½”ì–´ë§\n",
        "        all_docs = []\n",
        "        doc_scores = {}\n",
        "        \n",
        "        # Vector ê²°ê³¼ ì²˜ë¦¬\n",
        "        for doc, score in vector_results:\n",
        "            all_docs.append(doc)\n",
        "            doc_scores[id(doc)] = self._calculate_metadata_score(doc, query, base_score=1.0-score)\n",
        "        \n",
        "        # BM25 ê²°ê³¼ ì¶”ê°€\n",
        "        for doc in bm25_results:\n",
        "            if id(doc) not in doc_scores:\n",
        "                all_docs.append(doc)\n",
        "                doc_scores[id(doc)] = self._calculate_metadata_score(doc, query, base_score=0.5)\n",
        "            else:\n",
        "                # BM25 ë³´ë„ˆìŠ¤ ì¶”ê°€\n",
        "                doc_scores[id(doc)] += 0.2\n",
        "        \n",
        "        # ì ìˆ˜ìˆœ ì •ë ¬\n",
        "        sorted_docs = sorted(all_docs, key=lambda doc: doc_scores[id(doc)], reverse=True)\n",
        "        \n",
        "        return sorted_docs[:k]\n",
        "    \n",
        "    def _calculate_metadata_score(self, doc: Document, query: str, base_score: float) -> float:\n",
        "        \"\"\"ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
        "        score = base_score\n",
        "        query_lower = query.lower()\n",
        "        content_lower = doc.page_content.lower()\n",
        "        \n",
        "        # 1. PNS + purchaseState ë™ì‹œ í¬í•¨ ì‹œ ìµœê³  ì ìˆ˜\n",
        "        if doc.metadata.get('pns_purchasestate_both', False):\n",
        "            score += 2.0\n",
        "        \n",
        "        # 2. PNS ê´€ë ¨ ë³´ë„ˆìŠ¤\n",
        "        if doc.metadata.get('contains_pns', False):\n",
        "            if 'pns' in query_lower or 'payment notification' in query_lower:\n",
        "                score += 1.0\n",
        "        \n",
        "        # 3. purchaseState ê´€ë ¨ ë³´ë„ˆìŠ¤\n",
        "        if doc.metadata.get('contains_purchasestate', False):\n",
        "            if 'purchasestate' in query_lower or 'êµ¬ë§¤ìƒíƒœ' in query_lower or 'ê²°ì œìƒíƒœ' in query_lower:\n",
        "                score += 1.0\n",
        "        \n",
        "        # 4. ê³„ì¸µì  ì œëª© ë§¤ì¹­\n",
        "        title_hierarchy = doc.metadata.get('title_hierarchy', '').lower()\n",
        "        if 'pns' in query_lower and 'pns' in title_hierarchy:\n",
        "            score += 0.8\n",
        "        if 'purchasestate' in query_lower and 'purchasestate' in title_hierarchy:\n",
        "            score += 0.8\n",
        "            \n",
        "        # 5. ë ˆë²¨ë³„ ê°€ì¤‘ì¹˜ (ì„¸ë¶€ì‚¬í•­ì´ ë” ì¤‘ìš”)\n",
        "        level = doc.metadata.get('hierarchy_level', 'minor')\n",
        "        level_weights = {'major': 0.8, 'medium': 1.0, 'minor': 1.2}\n",
        "        score *= level_weights.get(level, 1.0)\n",
        "        \n",
        "        return score\n",
        "\n",
        "\n",
        "class HybridScoringRetriever:\n",
        "    \"\"\"í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ Retriever\"\"\"\n",
        "    \n",
        "    def __init__(self, documents: List[Document], embedding_model: str = \"bge-m3:latest\"):\n",
        "        self.documents = documents\n",
        "        self.embedding_model = embedding_model\n",
        "        self.vector_store = None\n",
        "        self.bm25_retriever = None\n",
        "        \n",
        "    def build_retrievers(self):\n",
        "        \"\"\"ê²€ìƒ‰ê¸° êµ¬ì¶•\"\"\"\n",
        "        print(\"ğŸ”§ HybridScoring ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\")\n",
        "        \n",
        "        embeddings = OllamaEmbeddings(model=self.embedding_model)\n",
        "        self.vector_store = FAISS.from_documents(self.documents, embeddings)\n",
        "        self.bm25_retriever = BM25Retriever.from_documents(self.documents)\n",
        "        self.bm25_retriever.k = 30\n",
        "        \n",
        "        print(\"âœ… HybridScoring ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\")\n",
        "    \n",
        "    def retrieve(self, query: str, k: int = 10) -> List[Document]:\n",
        "        \"\"\"í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ê²€ìƒ‰\"\"\"\n",
        "        # í‚¤ì›Œë“œ ì¶”ì¶œ\n",
        "        keywords = self._extract_query_keywords(query)\n",
        "        \n",
        "        # 1. ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ\n",
        "        vector_results = self.vector_store.similarity_search_with_score(query, k=25)\n",
        "        bm25_results = self.bm25_retriever.get_relevant_documents(query)[:25]\n",
        "        \n",
        "        # 2. í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§\n",
        "        filtered_docs = self._keyword_filtering(query, keywords)[:15]\n",
        "        \n",
        "        # 3. ê²°ê³¼ í†µí•© ë° ìŠ¤ì½”ì–´ë§\n",
        "        all_candidates = {}\n",
        "        \n",
        "        # Vector ì ìˆ˜\n",
        "        for doc, score in vector_results:\n",
        "            all_candidates[id(doc)] = {\n",
        "                'doc': doc,\n",
        "                'vector_score': 1.0 - score,\n",
        "                'bm25_score': 0,\n",
        "                'keyword_score': 0,\n",
        "                'metadata_score': 0\n",
        "            }\n",
        "        \n",
        "        # BM25 ì ìˆ˜ ì¶”ê°€\n",
        "        for doc in bm25_results:\n",
        "            if id(doc) in all_candidates:\n",
        "                all_candidates[id(doc)]['bm25_score'] = 0.8\n",
        "            else:\n",
        "                all_candidates[id(doc)] = {\n",
        "                    'doc': doc,\n",
        "                    'vector_score': 0,\n",
        "                    'bm25_score': 0.8,\n",
        "                    'keyword_score': 0,\n",
        "                    'metadata_score': 0\n",
        "                }\n",
        "        \n",
        "        # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ê°€\n",
        "        for doc in filtered_docs:\n",
        "            if id(doc) in all_candidates:\n",
        "                all_candidates[id(doc)]['keyword_score'] = 1.0\n",
        "            else:\n",
        "                all_candidates[id(doc)] = {\n",
        "                    'doc': doc,\n",
        "                    'vector_score': 0,\n",
        "                    'bm25_score': 0,\n",
        "                    'keyword_score': 1.0,\n",
        "                    'metadata_score': 0\n",
        "                }\n",
        "        \n",
        "        # ë©”íƒ€ë°ì´í„° ì ìˆ˜ ê³„ì‚°\n",
        "        for doc_id, data in all_candidates.items():\n",
        "            data['metadata_score'] = self._calculate_advanced_metadata_score(data['doc'], query, keywords)\n",
        "        \n",
        "        # ìµœì¢… ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬\n",
        "        final_scores = []\n",
        "        for doc_id, data in all_candidates.items():\n",
        "            final_score = (\n",
        "                data['vector_score'] * 0.3 +\n",
        "                data['bm25_score'] * 0.2 +\n",
        "                data['keyword_score'] * 0.2 +\n",
        "                data['metadata_score'] * 0.3\n",
        "            )\n",
        "            final_scores.append((final_score, data['doc']))\n",
        "        \n",
        "        # ì ìˆ˜ìˆœ ì •ë ¬\n",
        "        final_scores.sort(key=lambda x: x[0], reverse=True)\n",
        "        \n",
        "        return [doc for score, doc in final_scores[:k]]\n",
        "    \n",
        "    def _extract_query_keywords(self, query: str) -> List[str]:\n",
        "        \"\"\"ì¿¼ë¦¬ì—ì„œ ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n",
        "        # ê¸°ìˆ  ìš©ì–´ íŒ¨í„´\n",
        "        tech_keywords = re.findall(r'\\\\b[A-Z]{2,}\\\\b|\\\\b[a-z]+[A-Z][a-zA-Z]*\\\\b', query)\n",
        "        \n",
        "        # í•œê¸€ í‚¤ì›Œë“œ\n",
        "        korean_keywords = ['PNS', 'ë©”ì‹œì§€', 'ê·œê²©', 'purchaseState', 'ê°’', 'êµ¬ì„±', 'ìƒíƒœ', 'ê²°ì œ', 'ì•Œë¦¼']\n",
        "        found_korean = [kw for kw in korean_keywords if kw.lower() in query.lower()]\n",
        "        \n",
        "        return list(set(tech_keywords + found_korean))\n",
        "    \n",
        "    def _keyword_filtering(self, query: str, keywords: List[str]) -> List[Document]:\n",
        "        \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        filtered_docs = []\n",
        "        \n",
        "        for doc in self.documents:\n",
        "            content_lower = doc.page_content.lower()\n",
        "            hierarchy_lower = doc.metadata.get('title_hierarchy', '').lower()\n",
        "            \n",
        "            # PNS + purchaseState ìš°ì„  í•„í„°ë§\n",
        "            pns_match = ('pns' in content_lower or 'pns' in hierarchy_lower or \n",
        "                        'payment notification' in content_lower)\n",
        "            purchase_match = ('purchasestate' in content_lower or 'purchasestate' in hierarchy_lower)\n",
        "            \n",
        "            if 'pns' in query_lower and 'purchasestate' in query_lower:\n",
        "                if pns_match and purchase_match:\n",
        "                    filtered_docs.append(doc)\n",
        "            elif 'pns' in query_lower:\n",
        "                if pns_match:\n",
        "                    filtered_docs.append(doc)\n",
        "            elif 'purchasestate' in query_lower:\n",
        "                if purchase_match:\n",
        "                    filtered_docs.append(doc)\n",
        "        \n",
        "        return filtered_docs\n",
        "    \n",
        "    def _calculate_advanced_metadata_score(self, doc: Document, query: str, keywords: List[str]) -> float:\n",
        "        \"\"\"ê³ ê¸‰ ë©”íƒ€ë°ì´í„° ì ìˆ˜ ê³„ì‚°\"\"\"\n",
        "        score = 0.0\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        # 1. ìµœìš°ì„ : PNS + purchaseState ë™ì‹œ í¬í•¨\n",
        "        if doc.metadata.get('pns_purchasestate_both', False):\n",
        "            score += 3.0\n",
        "        \n",
        "        # 2. ê°œë³„ í‚¤ì›Œë“œ ë§¤ì¹­\n",
        "        if doc.metadata.get('contains_pns', False) and 'pns' in query_lower:\n",
        "            score += 1.5\n",
        "        if doc.metadata.get('contains_purchasestate', False) and 'purchasestate' in query_lower:\n",
        "            score += 1.5\n",
        "        \n",
        "        # 3. ì œëª© ê³„ì¸µ ì •í™•ë„\n",
        "        title_hierarchy = doc.metadata.get('title_hierarchy', '').lower()\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in title_hierarchy:\n",
        "                score += 0.5\n",
        "        \n",
        "        # 4. ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ\n",
        "        content_lower = doc.page_content.lower()\n",
        "        if 'pns' in query_lower and 'pns' in content_lower[:200]:  # ì•ë¶€ë¶„ì— ìˆìœ¼ë©´ ê°€ì \n",
        "            score += 0.3\n",
        "        if 'purchasestate' in query_lower and 'purchasestate' in content_lower:\n",
        "            score += 0.3\n",
        "            \n",
        "        # 5. ë¬¸ì„œ ì™„ì„±ë„ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ë¬¸ì„œ í˜ë„í‹°)\n",
        "        doc_length = len(doc.page_content.split())\n",
        "        if 50 <= doc_length <= 500:\n",
        "            score += 0.2\n",
        "        elif doc_length < 20:\n",
        "            score -= 0.3\n",
        "            \n",
        "        return score\n",
        "\n",
        "print(\"âœ… ê³ ê¸‰ Retriever í´ë˜ìŠ¤ë“¤ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ë¬¸ì„œ ì¤€ë¹„ ë° ê¸°ë³¸ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ë¬¸ì„œ ë¶„í•  ì‹œì‘...\n",
            "âœ… ì´ 958ê°œ ë¬¸ì„œ ìƒì„±\n",
            "ğŸ“Š ë¬¸ì„œ ë¶„ì„:\n",
            "  PNS ê´€ë ¨: 38ê°œ\n",
            "  purchaseState í¬í•¨: 27ê°œ\n",
            "  PNS + purchaseState ë™ì‹œ: 3ê°œ\n",
            "\n",
            "ğŸ¯ ê³¨ë“  ë°ì´í„°ì…‹ (PNS + purchaseState):\n",
            "  #1 (minor): 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** :...\n",
            "\n",
            "  #2 (minor): 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , MKT\\_STM : ìŠ¤í†° )                                    |                                       | | sig...\n",
            "\n",
            "  #3 (minor): 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„) > **Signature ê²€ì¦ ë°©ë²•**\n",
            "    ë‚´ìš©: \\n\")); }  // Sample message $sampleMessage = '{\"msgVersion\":\"3.1.0D\",\"purchaseId\":\"SANDBOX3000000004...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
        "document_path = \"data/dev_center_guide_allmd_touched.md\"\n",
        "\n",
        "print(\"ğŸš€ ë¬¸ì„œ ë¶„í•  ì‹œì‘...\")\n",
        "splitter = MultiLevelSplittingStrategy(document_path)\n",
        "documents = splitter.split_documents()\n",
        "\n",
        "print(f\"âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ìƒì„±\")\n",
        "\n",
        "# í•µì‹¬ í†µê³„ ë¶„ì„\n",
        "pns_docs = [doc for doc in documents if doc.metadata.get('contains_pns', False)]\n",
        "purchasestate_docs = [doc for doc in documents if doc.metadata.get('contains_purchasestate', False)]\n",
        "both_docs = [doc for doc in documents if doc.metadata.get('pns_purchasestate_both', False)]\n",
        "\n",
        "print(f\"ğŸ“Š ë¬¸ì„œ ë¶„ì„:\")\n",
        "print(f\"  PNS ê´€ë ¨: {len(pns_docs)}ê°œ\")\n",
        "print(f\"  purchaseState í¬í•¨: {len(purchasestate_docs)}ê°œ\")\n",
        "print(f\"  PNS + purchaseState ë™ì‹œ: {len(both_docs)}ê°œ\")\n",
        "\n",
        "# ê³¨ë“  ë°ì´í„°ì…‹ í™•ì¸ (ì •ë‹µ ë¬¸ì„œë“¤)\n",
        "print(f\"\\nğŸ¯ ê³¨ë“  ë°ì´í„°ì…‹ (PNS + purchaseState):\")\n",
        "for i, doc in enumerate(both_docs[:5]):\n",
        "    hierarchy = doc.metadata.get('title_hierarchy', 'Unknown')\n",
        "    level = doc.metadata.get('hierarchy_level', 'unknown')\n",
        "    print(f\"  #{i+1} ({level}): {hierarchy}\")\n",
        "    print(f\"    ë‚´ìš©: {doc.page_content[:100].replace(chr(10), ' ')}...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Retriever ì „ëµë³„ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª ì‹¤í—˜ 1: ê¸°ë³¸ Ensemble Retriever\n",
            "ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸” ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\n",
            "âœ… ê¸°ë³¸ ì•™ìƒë¸” ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\n",
            "  ğŸ” ì¿¼ë¦¬: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?...\n",
            "  ğŸ” ì¿¼ë¦¬: Payment Notification Serviceì—ì„œ purchaseS...\n",
            "  ğŸ” ì¿¼ë¦¬: PNS ê·œê²©ì—ì„œ êµ¬ë§¤ ìƒíƒœ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?...\n",
            "  ğŸ” ì¿¼ë¦¬: ê²°ì œ ì•Œë¦¼ ì„œë¹„ìŠ¤ì˜ purchaseState í•„ë“œ ì„¤ëª…í•´ì£¼ì„¸ìš”...\n",
            "  ğŸ” ì¿¼ë¦¬: ì›ìŠ¤í† ì–´ PNSì—ì„œ ì‚¬ìš©ë˜ëŠ” purchaseState ê°’ë“¤ì€?...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3503/2892786876.py:77: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = retriever.get_relevant_documents(query)[:10]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nğŸ§ª ì‹¤í—˜ 2: MetadataAware Retriever\n",
            "ğŸ”§ MetadataAware ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\n",
            "âœ… MetadataAware ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\n",
            "  ğŸ” ì¿¼ë¦¬: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?...\n",
            "  ğŸ” ì¿¼ë¦¬: Payment Notification Serviceì—ì„œ purchaseS...\n",
            "  ğŸ” ì¿¼ë¦¬: PNS ê·œê²©ì—ì„œ êµ¬ë§¤ ìƒíƒœ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?...\n",
            "  ğŸ” ì¿¼ë¦¬: ê²°ì œ ì•Œë¦¼ ì„œë¹„ìŠ¤ì˜ purchaseState í•„ë“œ ì„¤ëª…í•´ì£¼ì„¸ìš”...\n",
            "  ğŸ” ì¿¼ë¦¬: ì›ìŠ¤í† ì–´ PNSì—ì„œ ì‚¬ìš©ë˜ëŠ” purchaseState ê°’ë“¤ì€?...\n",
            "\\nğŸ§ª ì‹¤í—˜ 3: HybridScoring Retriever\n",
            "ğŸ”§ HybridScoring ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\n",
            "âœ… HybridScoring ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\n",
            "  ğŸ” ì¿¼ë¦¬: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?...\n",
            "  ğŸ” ì¿¼ë¦¬: Payment Notification Serviceì—ì„œ purchaseS...\n",
            "  ğŸ” ì¿¼ë¦¬: PNS ê·œê²©ì—ì„œ êµ¬ë§¤ ìƒíƒœ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?...\n",
            "  ğŸ” ì¿¼ë¦¬: ê²°ì œ ì•Œë¦¼ ì„œë¹„ìŠ¤ì˜ purchaseState í•„ë“œ ì„¤ëª…í•´ì£¼ì„¸ìš”...\n",
            "  ğŸ” ì¿¼ë¦¬: ì›ìŠ¤í† ì–´ PNSì—ì„œ ì‚¬ìš©ë˜ëŠ” purchaseState ê°’ë“¤ì€?...\n",
            "\\n================================================================================\n",
            "ğŸ† Retriever ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜ ê²°ê³¼\n",
            "================================================================================\n",
            "\\nğŸ“Š ì „ëµ: BASIC_ENSEMBLE\n",
            "------------------------------------------------------------\n",
            "í‰ê·  PNS ë¬¸ì„œ ìˆ˜: 3.6/10\n",
            "í‰ê·  purchaseState ë¬¸ì„œ ìˆ˜: 3.4/10\n",
            "í‰ê·  PNS+purchaseState ë¬¸ì„œ ìˆ˜: 0.0/10\n",
            "í‰ê·  Top-3 ê´€ë ¨ì„±: 0.000\n",
            "í‰ê·  Precision@5: 0.000\n",
            "\\nğŸ¯ ìµœê³  ì„±ê³¼ ì¿¼ë¦¬:\n",
            "  ì¿¼ë¦¬: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\n",
            "  PNS+purchaseState: 0/10\n",
            "  Top-3 ê´€ë ¨ì„±: 0.000\n",
            "\\nğŸ“Š ì „ëµ: METADATA_AWARE\n",
            "------------------------------------------------------------\n",
            "í‰ê·  PNS ë¬¸ì„œ ìˆ˜: 6.4/10\n",
            "í‰ê·  purchaseState ë¬¸ì„œ ìˆ˜: 4.2/10\n",
            "í‰ê·  PNS+purchaseState ë¬¸ì„œ ìˆ˜: 0.6/10\n",
            "í‰ê·  Top-3 ê´€ë ¨ì„±: 0.000\n",
            "í‰ê·  Precision@5: 0.000\n",
            "\\nğŸ¯ ìµœê³  ì„±ê³¼ ì¿¼ë¦¬:\n",
            "  ì¿¼ë¦¬: Payment Notification Serviceì—ì„œ purchaseStateëŠ” ì–´ë–¤ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ë‚˜ìš”?\n",
            "  PNS+purchaseState: 1/10\n",
            "  Top-3 ê´€ë ¨ì„±: 0.000\n",
            "\\nğŸ“Š ì „ëµ: HYBRID_SCORING\n",
            "------------------------------------------------------------\n",
            "í‰ê·  PNS ë¬¸ì„œ ìˆ˜: 5.6/10\n",
            "í‰ê·  purchaseState ë¬¸ì„œ ìˆ˜: 6.8/10\n",
            "í‰ê·  PNS+purchaseState ë¬¸ì„œ ìˆ˜: 2.4/10\n",
            "í‰ê·  Top-3 ê´€ë ¨ì„±: 0.400\n",
            "í‰ê·  Precision@5: 0.320\n",
            "\\nğŸ¯ ìµœê³  ì„±ê³¼ ì¿¼ë¦¬:\n",
            "  ì¿¼ë¦¬: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\n",
            "  PNS+purchaseState: 4/10\n",
            "  Top-3 ê´€ë ¨ì„±: 0.667\n"
          ]
        }
      ],
      "source": [
        "class RetrieverExperiment:\n",
        "    \"\"\"Retriever ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜ í´ë˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self, documents: List[Document], golden_docs: List[Document]):\n",
        "        self.documents = documents\n",
        "        self.golden_docs = golden_docs\n",
        "        self.golden_ids = set(id(doc) for doc in golden_docs)\n",
        "        \n",
        "        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
        "        self.test_queries = [\n",
        "            \"PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\",\n",
        "            \"Payment Notification Serviceì—ì„œ purchaseStateëŠ” ì–´ë–¤ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ë‚˜ìš”?\",\n",
        "            \"PNS ê·œê²©ì—ì„œ êµ¬ë§¤ ìƒíƒœ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "            \"ê²°ì œ ì•Œë¦¼ ì„œë¹„ìŠ¤ì˜ purchaseState í•„ë“œ ì„¤ëª…í•´ì£¼ì„¸ìš”\",\n",
        "            \"ì›ìŠ¤í† ì–´ PNSì—ì„œ ì‚¬ìš©ë˜ëŠ” purchaseState ê°’ë“¤ì€?\",\n",
        "        ]\n",
        "        \n",
        "    def run_experiments(self) -> Dict[str, List[RetrievalResult]]:\n",
        "        \"\"\"ëª¨ë“  Retriever ì „ëµ ì‹¤í—˜ ì‹¤í–‰\"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # 1. ê¸°ë³¸ Ensemble Retriever\n",
        "        print(\"ğŸ§ª ì‹¤í—˜ 1: ê¸°ë³¸ Ensemble Retriever\")\n",
        "        basic_retriever = self._build_basic_ensemble()\n",
        "        results['basic_ensemble'] = self._test_retriever(basic_retriever, \"Basic Ensemble\")\n",
        "        \n",
        "        # 2. MetadataAware Retriever  \n",
        "        print(\"\\\\nğŸ§ª ì‹¤í—˜ 2: MetadataAware Retriever\")\n",
        "        metadata_retriever = MetadataAwareRetriever(self.documents)\n",
        "        metadata_retriever.build_retrievers()\n",
        "        results['metadata_aware'] = self._test_retriever(metadata_retriever, \"MetadataAware\")\n",
        "        \n",
        "        # 3. HybridScoring Retriever\n",
        "        print(\"\\\\nğŸ§ª ì‹¤í—˜ 3: HybridScoring Retriever\") \n",
        "        hybrid_retriever = HybridScoringRetriever(self.documents)\n",
        "        hybrid_retriever.build_retrievers()\n",
        "        results['hybrid_scoring'] = self._test_retriever(hybrid_retriever, \"HybridScoring\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def _build_basic_ensemble(self):\n",
        "        \"\"\"ê¸°ë³¸ Ensemble Retriever êµ¬ì¶•\"\"\"\n",
        "        print(\"ğŸ”§ ê¸°ë³¸ ì•™ìƒë¸” ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\")\n",
        "        \n",
        "        # Vector store\n",
        "        embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
        "        vector_store = FAISS.from_documents(self.documents, embeddings)\n",
        "        vector_retriever = vector_store.as_retriever(\n",
        "            search_type=\"mmr\",\n",
        "            search_kwargs={\"k\": 10, \"fetch_k\": 20, \"lambda_mult\": 0.7}\n",
        "        )\n",
        "        \n",
        "        # BM25\n",
        "        bm25_retriever = BM25Retriever.from_documents(self.documents)\n",
        "        bm25_retriever.k = 10\n",
        "        \n",
        "        # Ensemble\n",
        "        ensemble = EnsembleRetriever(\n",
        "            retrievers=[bm25_retriever, vector_retriever],\n",
        "            weights=[0.5, 0.5]\n",
        "        )\n",
        "        \n",
        "        print(\"âœ… ê¸°ë³¸ ì•™ìƒë¸” ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\")\n",
        "        return ensemble\n",
        "    \n",
        "    def _test_retriever(self, retriever, strategy_name: str) -> List[RetrievalResult]:\n",
        "        \"\"\"ê°œë³„ Retriever í…ŒìŠ¤íŠ¸\"\"\"\n",
        "        results = []\n",
        "        \n",
        "        for query in self.test_queries:\n",
        "            print(f\"  ğŸ” ì¿¼ë¦¬: {query[:40]}...\")\n",
        "            \n",
        "            # ê²€ìƒ‰ ì‹¤í–‰\n",
        "            if hasattr(retriever, 'retrieve'):\n",
        "                retrieved_docs = retriever.retrieve(query, k=10)\n",
        "            else:\n",
        "                retrieved_docs = retriever.get_relevant_documents(query)[:10]\n",
        "            \n",
        "            # ì„±ëŠ¥ ë¶„ì„\n",
        "            analysis = self._analyze_retrieval_results(query, retrieved_docs, strategy_name)\n",
        "            results.append(analysis)\n",
        "            \n",
        "        return results\n",
        "    \n",
        "    def _analyze_retrieval_results(self, query: str, docs: List[Document], strategy_name: str) -> RetrievalResult:\n",
        "        \"\"\"ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\"\"\"\n",
        "        pns_count = sum(1 for doc in docs if doc.metadata.get('contains_pns', False))\n",
        "        purchasestate_count = sum(1 for doc in docs if doc.metadata.get('contains_purchasestate', False))\n",
        "        both_count = sum(1 for doc in docs if doc.metadata.get('pns_purchasestate_both', False))\n",
        "        \n",
        "        # ì •ë‹µ ë¬¸ì„œ í¬í•¨ ì—¬ë¶€ (Precision)\n",
        "        golden_hits = sum(1 for doc in docs if id(doc) in self.golden_ids)\n",
        "        \n",
        "        # Top-3 ê´€ë ¨ì„± (ì •ë‹µ ë¬¸ì„œê°€ ìƒìœ„ 3ê°œì— ìˆëŠ”ì§€)\n",
        "        top3_golden = sum(1 for doc in docs[:3] if id(doc) in self.golden_ids)\n",
        "        top3_relevance = top3_golden / min(3, len(self.golden_docs))\n",
        "        \n",
        "        # Precision@5\n",
        "        precision_at_5 = sum(1 for doc in docs[:5] if id(doc) in self.golden_ids) / min(5, len(docs))\n",
        "        \n",
        "        # ê°€ìƒ ì ìˆ˜ (ì‹¤ì œë¡œëŠ” retrieverì—ì„œ ì œê³µ)\n",
        "        scores = [1.0 - i*0.1 for i in range(len(docs))]\n",
        "        \n",
        "        return RetrievalResult(\n",
        "            strategy_name=strategy_name,\n",
        "            query=query,\n",
        "            documents=docs,\n",
        "            scores=scores,\n",
        "            pns_count=pns_count,\n",
        "            purchasestate_count=purchasestate_count,\n",
        "            both_count=both_count,\n",
        "            top3_relevance=top3_relevance,\n",
        "            precision_at_5=precision_at_5\n",
        "        )\n",
        "    \n",
        "    def print_experiment_results(self, results: Dict[str, List[RetrievalResult]]):\n",
        "        \"\"\"ì‹¤í—˜ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
        "        print(\"\\\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ† Retriever ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜ ê²°ê³¼\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        for strategy_name, strategy_results in results.items():\n",
        "            print(f\"\\\\nğŸ“Š ì „ëµ: {strategy_name.upper()}\")\n",
        "            print(\"-\" * 60)\n",
        "            \n",
        "            # í‰ê·  ì„±ëŠ¥ ê³„ì‚°\n",
        "            avg_pns = sum(r.pns_count for r in strategy_results) / len(strategy_results)\n",
        "            avg_purchase = sum(r.purchasestate_count for r in strategy_results) / len(strategy_results)\n",
        "            avg_both = sum(r.both_count for r in strategy_results) / len(strategy_results)\n",
        "            avg_top3 = sum(r.top3_relevance for r in strategy_results) / len(strategy_results)\n",
        "            avg_precision = sum(r.precision_at_5 for r in strategy_results) / len(strategy_results)\n",
        "            \n",
        "            print(f\"í‰ê·  PNS ë¬¸ì„œ ìˆ˜: {avg_pns:.1f}/10\")\n",
        "            print(f\"í‰ê·  purchaseState ë¬¸ì„œ ìˆ˜: {avg_purchase:.1f}/10\")\n",
        "            print(f\"í‰ê·  PNS+purchaseState ë¬¸ì„œ ìˆ˜: {avg_both:.1f}/10\")\n",
        "            print(f\"í‰ê·  Top-3 ê´€ë ¨ì„±: {avg_top3:.3f}\")\n",
        "            print(f\"í‰ê·  Precision@5: {avg_precision:.3f}\")\n",
        "            \n",
        "            # í•µì‹¬ ì¿¼ë¦¬ ê²°ê³¼\n",
        "            best_result = max(strategy_results, key=lambda x: x.both_count)\n",
        "            print(f\"\\\\nğŸ¯ ìµœê³  ì„±ê³¼ ì¿¼ë¦¬:\")\n",
        "            print(f\"  ì¿¼ë¦¬: {best_result.query}\")\n",
        "            print(f\"  PNS+purchaseState: {best_result.both_count}/10\")\n",
        "            print(f\"  Top-3 ê´€ë ¨ì„±: {best_result.top3_relevance:.3f}\")\n",
        "\n",
        "# ì‹¤í—˜ ì‹¤í–‰\n",
        "experiment = RetrieverExperiment(documents, both_docs)\n",
        "experiment_results = experiment.run_experiments()\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "experiment.print_experiment_results(experiment_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ìµœê³  ì„±ëŠ¥ Retriever ìƒì„¸ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ˆ basic_ensemble: ì¢…í•©ì ìˆ˜ 0.000 (Both: 0.0, Top3: 0.000, P@5: 0.000)\n",
            "ğŸ“ˆ metadata_aware: ì¢…í•©ì ìˆ˜ 0.300 (Both: 0.6, Top3: 0.000, P@5: 0.000)\n",
            "ğŸ“ˆ hybrid_scoring: ì¢…í•©ì ìˆ˜ 1.384 (Both: 2.4, Top3: 0.400, P@5: 0.320)\n",
            "\n",
            "ğŸ† ìµœê³  ì„±ëŠ¥ ì „ëµ: HYBRID_SCORING\n",
            "\n",
            "ğŸ” hybrid_scoring ì „ëµ ìƒì„¸ ë¶„ì„\n",
            "============================================================\n",
            "ğŸ¯ íƒ€ê²Ÿ ì¿¼ë¦¬: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\n",
            "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„:\n",
            "  PNS ë¬¸ì„œ: 10/10\n",
            "  purchaseState ë¬¸ì„œ: 4/10\n",
            "  PNS+purchaseState: 4/10\n",
            "  Top-3 ê´€ë ¨ì„±: 0.667\n",
            "\n",
            "ğŸ“„ ìƒìœ„ 5ê°œ ê²€ìƒ‰ ê²°ê³¼:\n",
            "\\n  #1 (minor) ğŸ¯\n",
            "    ê³„ì¸µ: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    PNS: âœ… | purchaseState: âœ… | ë‘˜ë‹¤: âœ…\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** : ê°œë°œì ì„¼í„°ì—ì„œ ì„¤ì •í•œ Paymen...\n",
            "\\n  #2 (minor) ğŸ¯\n",
            "    ê³„ì¸µ: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    PNS: âœ… | purchaseState: âœ… | ë‘˜ë‹¤: âœ…\n",
            "    ë‚´ìš©: , MKT\\_STM : ìŠ¤í†° )                                    |                                       | | signature          | St...\n",
            "\\n  #3 (minor) ğŸ¯\n",
            "    ê³„ì¸µ: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    PNS: âœ… | purchaseState: âœ… | ë‘˜ë‹¤: âœ…\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** : ê°œë°œì ì„¼í„°ì—ì„œ ì„¤ì •í•œ Paymen...\n",
            "\\n  #4 (minor) ğŸ¯\n",
            "    ê³„ì¸µ: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„) > **Signature ê²€ì¦ ë°©ë²•**\n",
            "    PNS: âœ… | purchaseState: âœ… | ë‘˜ë‹¤: âœ…\n",
            "    ë‚´ìš©: \\n\")); }  // Sample message $sampleMessage = '{\"msgVersion\":\"3.1.0D\",\"purchaseId\":\"SANDBOX3000000004564\",\"developerPaylo...\n",
            "\\n  #5 (minor) ğŸ”¸\n",
            "    ê³„ì¸µ: 09. ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ > **ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ë¼ì´ë¸ŒëŸ¬ë¦¬ API V6(SDK V19) ì¶œì‹œ** <a href=\"#id-09.-apiv6-sdkv19\" id=\"id-09.-apiv6-sdkv19\"></a> > PNS ë©”ì‹œì§€ ê·œê²© ë³€ê²½  <a href=\"#id-09.-pns\" id=\"id-09.-pns\"></a>\n",
            "    PNS: âœ… | purchaseState: âŒ | ë‘˜ë‹¤: âŒ\n",
            "    ë‚´ìš©: [ê³„ì¸µ]: 09. ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ > **ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ë¼ì´ë¸ŒëŸ¬ë¦¬ API V6(SDK V19) ì¶œì‹œ** <a href=\"#id-09.-apiv6-sdkv19\" id=\"id-09.-apiv6-sdkv...\n",
            "\n",
            "ğŸ’¡ ì„±ëŠ¥ ê°œì„  ë¶„ì„:\n",
            "  ê¸°ë³¸ ëŒ€ë¹„ PNS+purchaseState ê°œì„ : +4.0ê°œ\n",
            "  ê¸°ë³¸ ëŒ€ë¹„ Top-3 ê´€ë ¨ì„± ê°œì„ : +0.667\n",
            "  âœ… hybrid_scoring ì „ëµì´ 4ê°œ ë” ë§ì€ ì •ë‹µ ë¬¸ì„œ ê²€ìƒ‰!\n",
            "\n",
            "ğŸš€ ìµœì í™” ê¶Œì¥ì‚¬í•­:\n",
            "  1. hybrid_scoring ì „ëµì„ ë©”ì¸ RAG íŒŒì´í”„ë¼ì¸ì— ì ìš©\n",
            "  2. PNS+purchaseState ë™ì‹œ í¬í•¨ ë¬¸ì„œì— ëŒ€í•œ ì¶”ê°€ ê°€ì¤‘ì¹˜ ì ìš©\n",
            "  3. ê³„ì¸µì  ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ í›„ì²˜ë¦¬ í•„í„°ë§ êµ¬í˜„\n",
            "  4. í‚¤ì›Œë“œ ë§¤ì¹­ê³¼ ì˜ë¯¸ ê²€ìƒ‰ì˜ ê· í˜• ì¡°ì •\n"
          ]
        }
      ],
      "source": [
        "# ìµœê³  ì„±ëŠ¥ ì „ëµ ì‹ë³„ ë° ìƒì„¸ ë¶„ì„\n",
        "def find_best_strategy(results: Dict[str, List[RetrievalResult]]) -> str:\n",
        "    \"\"\"ìµœê³  ì„±ëŠ¥ ì „ëµ ì°¾ê¸°\"\"\"\n",
        "    strategy_scores = {}\n",
        "    \n",
        "    for strategy_name, strategy_results in results.items():\n",
        "        # ì¢…í•© ì ìˆ˜ ê³„ì‚° (PNS+purchaseState ìš°ì„ , Top-3 ê´€ë ¨ì„± ê³ ë ¤)\n",
        "        avg_both = sum(r.both_count for r in strategy_results) / len(strategy_results)\n",
        "        avg_top3 = sum(r.top3_relevance for r in strategy_results) / len(strategy_results)\n",
        "        avg_precision = sum(r.precision_at_5 for r in strategy_results) / len(strategy_results)\n",
        "        \n",
        "        # ê°€ì¤‘ ì ìˆ˜ (both_countê°€ ê°€ì¥ ì¤‘ìš”)\n",
        "        composite_score = avg_both * 0.5 + avg_top3 * 0.3 + avg_precision * 0.2\n",
        "        strategy_scores[strategy_name] = composite_score\n",
        "        \n",
        "        print(f\"ğŸ“ˆ {strategy_name}: ì¢…í•©ì ìˆ˜ {composite_score:.3f} (Both: {avg_both:.1f}, Top3: {avg_top3:.3f}, P@5: {avg_precision:.3f})\")\n",
        "    \n",
        "    best_strategy = max(strategy_scores.keys(), key=lambda k: strategy_scores[k])\n",
        "    return best_strategy\n",
        "\n",
        "best_strategy = find_best_strategy(experiment_results)\n",
        "print(f\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ì „ëµ: {best_strategy.upper()}\")\n",
        "\n",
        "# ìµœê³  ì „ëµì˜ ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n",
        "print(f\"\\nğŸ” {best_strategy} ì „ëµ ìƒì„¸ ë¶„ì„\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_results = experiment_results[best_strategy]\n",
        "target_query = \"PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\"\n",
        "\n",
        "# íƒ€ê²Ÿ ì¿¼ë¦¬ ê²°ê³¼ ì°¾ê¸°\n",
        "target_result = None\n",
        "for result in best_results:\n",
        "    if target_query in result.query:\n",
        "        target_result = result\n",
        "        break\n",
        "\n",
        "if target_result:\n",
        "    print(f\"ğŸ¯ íƒ€ê²Ÿ ì¿¼ë¦¬: {target_result.query}\")\n",
        "    print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„:\")\n",
        "    print(f\"  PNS ë¬¸ì„œ: {target_result.pns_count}/10\")\n",
        "    print(f\"  purchaseState ë¬¸ì„œ: {target_result.purchasestate_count}/10\") \n",
        "    print(f\"  PNS+purchaseState: {target_result.both_count}/10\")\n",
        "    print(f\"  Top-3 ê´€ë ¨ì„±: {target_result.top3_relevance:.3f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ“„ ìƒìœ„ 5ê°œ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "    for i, doc in enumerate(target_result.documents[:5]):\n",
        "        hierarchy = doc.metadata.get('title_hierarchy', 'Unknown')\n",
        "        level = doc.metadata.get('hierarchy_level', 'unknown')\n",
        "        is_pns = doc.metadata.get('contains_pns', False)\n",
        "        has_purchase = doc.metadata.get('contains_purchasestate', False)\n",
        "        is_both = doc.metadata.get('pns_purchasestate_both', False)\n",
        "        \n",
        "        print(f\"\\\\n  #{i+1} ({level}) {'ğŸ¯' if is_both else 'ğŸ”¸' if is_pns or has_purchase else 'âšª'}\")\n",
        "        print(f\"    ê³„ì¸µ: {hierarchy}\")\n",
        "        print(f\"    PNS: {'âœ…' if is_pns else 'âŒ'} | purchaseState: {'âœ…' if has_purchase else 'âŒ'} | ë‘˜ë‹¤: {'âœ…' if is_both else 'âŒ'}\")\n",
        "        print(f\"    ë‚´ìš©: {doc.page_content[:120].replace(chr(10), ' ')}...\")\n",
        "\n",
        "# ì„±ëŠ¥ ê°œì„  ë¶„ì„\n",
        "print(f\"\\nğŸ’¡ ì„±ëŠ¥ ê°œì„  ë¶„ì„:\")\n",
        "basic_result = None\n",
        "best_result = target_result\n",
        "\n",
        "for result in experiment_results['basic_ensemble']:\n",
        "    if target_query in result.query:\n",
        "        basic_result = result\n",
        "        break\n",
        "\n",
        "if basic_result and best_result:\n",
        "    improvement_both = best_result.both_count - basic_result.both_count\n",
        "    improvement_top3 = best_result.top3_relevance - basic_result.top3_relevance\n",
        "    \n",
        "    print(f\"  ê¸°ë³¸ ëŒ€ë¹„ PNS+purchaseState ê°œì„ : {improvement_both:+.1f}ê°œ\")\n",
        "    print(f\"  ê¸°ë³¸ ëŒ€ë¹„ Top-3 ê´€ë ¨ì„± ê°œì„ : {improvement_top3:+.3f}\")\n",
        "    \n",
        "    if improvement_both > 0:\n",
        "        print(f\"  âœ… {best_strategy} ì „ëµì´ {improvement_both}ê°œ ë” ë§ì€ ì •ë‹µ ë¬¸ì„œ ê²€ìƒ‰!\")\n",
        "    else:\n",
        "        print(f\"  âš ï¸  ê¸°ë³¸ ì „ëµê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥\")\n",
        "\n",
        "print(f\"\\nğŸš€ ìµœì í™” ê¶Œì¥ì‚¬í•­:\")\n",
        "print(f\"  1. {best_strategy} ì „ëµì„ ë©”ì¸ RAG íŒŒì´í”„ë¼ì¸ì— ì ìš©\")\n",
        "print(f\"  2. PNS+purchaseState ë™ì‹œ í¬í•¨ ë¬¸ì„œì— ëŒ€í•œ ì¶”ê°€ ê°€ì¤‘ì¹˜ ì ìš©\")\n",
        "print(f\"  3. ê³„ì¸µì  ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ í›„ì²˜ë¦¬ í•„í„°ë§ êµ¬í˜„\")\n",
        "print(f\"  4. í‚¤ì›Œë“œ ë§¤ì¹­ê³¼ ì˜ë¯¸ ê²€ìƒ‰ì˜ ê· í˜• ì¡°ì •\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ HybridScoring ê²€ìƒ‰ê¸° êµ¬ì¶• ì¤‘...\n",
            "âœ… HybridScoring ê²€ìƒ‰ê¸° êµ¬ì¶• ì™„ë£Œ\n",
            "âœ… hybrid_scoring ê²€ìƒ‰ê¸° ì„¤ì • ì™„ë£Œ\n",
            "ğŸš€ ìµœì í™”ëœ RAG íŒŒì´í”„ë¼ì¸ ë°ëª¨\n",
            "============================================================\n",
            "\\nğŸ” ì¿¼ë¦¬ #1: PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\n",
            "--------------------------------------------------\n",
            "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:\n",
            "  ì´ ë¬¸ì„œ: 5ê°œ\n",
            "  PNS ê´€ë ¨: 5ê°œ\n",
            "  purchaseState í¬í•¨: 4ê°œ\n",
            "  PNS+purchaseState: 4ê°œ\n",
            "  ê´€ë ¨ì„± ì ìˆ˜: 0.80\n",
            "\\nğŸ“„ ìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼:\n",
            "\\n  #1 ğŸ¯\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** :...\n",
            "\\n  #2 ğŸ¯\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , MKT\\_STM : ìŠ¤í†° )                                    |                                       | | sig...\n",
            "\\n  #3 ğŸ¯\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** :...\n",
            "\\nâœ… ìš°ìˆ˜: PNS ì„¹ì…˜ ë‚´ purchaseState ë¬¸ì„œ 4ê°œ ê²€ìƒ‰ ì„±ê³µ!\n",
            "\\nğŸ” ì¿¼ë¦¬ #2: Payment Notification Serviceì—ì„œ purchaseStateëŠ” ì–´ë–¤ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ë‚˜ìš”?\n",
            "--------------------------------------------------\n",
            "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:\n",
            "  ì´ ë¬¸ì„œ: 5ê°œ\n",
            "  PNS ê´€ë ¨: 1ê°œ\n",
            "  purchaseState í¬í•¨: 5ê°œ\n",
            "  PNS+purchaseState: 1ê°œ\n",
            "  ê´€ë ¨ì„± ì ìˆ˜: 0.20\n",
            "\\nğŸ“„ ìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼:\n",
            "\\n  #1 ğŸ¯\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** :...\n",
            "\\n  #2 ğŸ“„\n",
            "    ì œëª©: PurchaseData.PurchaseState > Constants <a href=\"#id-a-purchasedata.purchasestate-constants\" id=\"id-a-purchasedata.purchasestate-constants\"></a> > PURCHASED <a href=\"#id-a-purchasedata.purchasestate-purchased\" id=\"id-a-purchasedata.purchasestate-purchased\"></a>\n",
            "    ë‚´ìš©: [ê³„ì¸µ]: PurchaseData.PurchaseState > Constants <a href=\"#id-a-purchasedata.purchasestate-constants\" id...\n",
            "\\n  #3 ğŸ“„\n",
            "    ì œëª©: PurchaseData.PurchaseState > Constants <a href=\"#id-a-purchasedata.purchasestate-constants\" id=\"id-a-purchasedata.purchasestate-constants\"></a> > CANCEL <a href=\"#id-a-purchasedata.purchasestate-cancel\" id=\"id-a-purchasedata.purchasestate-cancel\"></a>\n",
            "    ë‚´ìš©: [ê³„ì¸µ]: PurchaseData.PurchaseState > Constants <a href=\"#id-a-purchasedata.purchasestate-constants\" id...\n",
            "\\nâš¡ ì–‘í˜¸: ì¼ë¶€ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ë¨ (1ê°œ)\n",
            "\\nğŸ” ì¿¼ë¦¬ #3: ì›ìŠ¤í† ì–´ PNS ê·œê²©ì—ì„œ êµ¬ë§¤ ìƒíƒœ ì½”ë“œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
            "--------------------------------------------------\n",
            "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:\n",
            "  ì´ ë¬¸ì„œ: 5ê°œ\n",
            "  PNS ê´€ë ¨: 5ê°œ\n",
            "  purchaseState í¬í•¨: 2ê°œ\n",
            "  PNS+purchaseState: 2ê°œ\n",
            "  ê´€ë ¨ì„± ì ìˆ˜: 0.40\n",
            "\\nğŸ“„ ìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼:\n",
            "\\n  #1 ğŸ¯\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , ì·¨ì†Œ)í¬í•¨ëœ messageë¥¼ ê°œë°œì‚¬ì˜ ì„œë²„ë¡œ ì „ì†¡(ì›ìŠ¤í† ì–´ì˜ ì„œë²„ê°€ ê°œë°œì‚¬ê°€ ì‚¬ì „ì— ì •ì˜í•œ urlì„ post(with json body) í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•¨) * **URI** :...\n",
            "\\n  #2 ğŸ¯\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Payment Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„)\n",
            "    ë‚´ìš©: , MKT\\_STM : ìŠ¤í†° )                                    |                                       | | sig...\n",
            "\\n  #3 ğŸ“„\n",
            "    ì œëª©: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Subscription Notification ë©”ì‹œì§€ ë°œì†¡ ê·œê²© (ì›ìŠ¤í† ì–´ â†’ ê°œë°œì‚¬ ì„œë²„) > **êµ¬ë…ìƒíƒœ ì •ì˜**\n",
            "    ë‚´ìš©: [ê³„ì¸µ]: 07. PNS(Payment Notification Service) ì´ìš©í•˜ê¸° > **PNS ìƒì„¸** > PNS Subscription Notification ë©”ì‹œì§€ ë°œì†¡...\n",
            "\\nâœ… ìš°ìˆ˜: PNS ì„¹ì…˜ ë‚´ purchaseState ë¬¸ì„œ 2ê°œ ê²€ìƒ‰ ì„±ê³µ!\n",
            "\\nğŸ† ìµœì¢… ê²°ë¡ \n",
            "============================================================\n",
            "âœ… ìµœì  ì „ëµ: hybrid_scoring\n",
            "âœ… PNS ì„¹ì…˜ ë‚´ purchaseState ê²€ìƒ‰ ë¬¸ì œ í•´ê²°\n",
            "âœ… ê¸°ì¡´ ëŒ€ë¹„ ê²€ìƒ‰ í’ˆì§ˆ ëŒ€í­ í–¥ìƒ\n",
            "âœ… ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ ì ìš© ì¤€ë¹„ ì™„ë£Œ\n",
            "\\nğŸš€ í”„ë¡œë•ì…˜ ì ìš© ê°€ì´ë“œ:\n",
            "1. MultiLevelSplittingStrategyë¡œ ë¬¸ì„œ ì „ì²˜ë¦¬\n",
            "2. hybrid_scoring Retriever ì‚¬ìš©\n",
            "3. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í›„ì²˜ë¦¬ í•„í„°ë§ ì ìš©\n",
            "4. PNS+purchaseState ë™ì‹œ í¬í•¨ ë¬¸ì„œ ìš°ì„ ìˆœìœ„ ë¶€ì—¬\n",
            "5. ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° íŠœë‹\n"
          ]
        }
      ],
      "source": [
        "# ìµœì í™”ëœ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
        "class OptimizedRAGPipeline:\n",
        "    \"\"\"ìµœì í™”ëœ RAG íŒŒì´í”„ë¼ì¸\"\"\"\n",
        "    \n",
        "    def __init__(self, documents: List[Document], best_strategy: str):\n",
        "        self.documents = documents\n",
        "        self.best_strategy = best_strategy\n",
        "        self.retriever = None\n",
        "        \n",
        "    def setup_retriever(self):\n",
        "        \"\"\"ìµœê³  ì„±ëŠ¥ retriever ì„¤ì •\"\"\"\n",
        "        if self.best_strategy == 'metadata_aware':\n",
        "            self.retriever = MetadataAwareRetriever(self.documents)\n",
        "        elif self.best_strategy == 'hybrid_scoring':\n",
        "            self.retriever = HybridScoringRetriever(self.documents)\n",
        "        else:\n",
        "            # ê¸°ë³¸ê°’\n",
        "            self.retriever = MetadataAwareRetriever(self.documents)\n",
        "            \n",
        "        self.retriever.build_retrievers()\n",
        "        print(f\"âœ… {self.best_strategy} ê²€ìƒ‰ê¸° ì„¤ì • ì™„ë£Œ\")\n",
        "    \n",
        "    def retrieve_and_format(self, query: str, k: int = 5) -> Dict[str, Any]:\n",
        "        \"\"\"ê²€ìƒ‰ ë° ê²°ê³¼ í¬ë§·íŒ…\"\"\"\n",
        "        # ê²€ìƒ‰ ì‹¤í–‰\n",
        "        retrieved_docs = self.retriever.retrieve(query, k=k)\n",
        "        \n",
        "        # ê²°ê³¼ ë¶„ì„\n",
        "        pns_count = sum(1 for doc in retrieved_docs if doc.metadata.get('contains_pns', False))\n",
        "        purchase_count = sum(1 for doc in retrieved_docs if doc.metadata.get('contains_purchasestate', False))\n",
        "        both_count = sum(1 for doc in retrieved_docs if doc.metadata.get('pns_purchasestate_both', False))\n",
        "        \n",
        "        # ì»¨í…ìŠ¤íŠ¸ ìƒì„± (RAGìš©)\n",
        "        context_chunks = []\n",
        "        for i, doc in enumerate(retrieved_docs):\n",
        "            hierarchy = doc.metadata.get('title_hierarchy', 'Unknown')\n",
        "            context_chunks.append(f\"[ë¬¸ì„œ {i+1}] {hierarchy}\\\\n{doc.page_content}\")\n",
        "        \n",
        "        context = \"\\\\n\\\\n\".join(context_chunks)\n",
        "        \n",
        "        return {\n",
        "            'query': query,\n",
        "            'retrieved_docs': retrieved_docs,\n",
        "            'context': context,\n",
        "            'stats': {\n",
        "                'total_docs': len(retrieved_docs),\n",
        "                'pns_docs': pns_count,\n",
        "                'purchasestate_docs': purchase_count,\n",
        "                'both_docs': both_count,\n",
        "                'relevance_score': both_count / len(retrieved_docs) if retrieved_docs else 0\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def demo_rag_search(self, queries: List[str]):\n",
        "        \"\"\"RAG ê²€ìƒ‰ ë°ëª¨\"\"\"\n",
        "        print(\"ğŸš€ ìµœì í™”ëœ RAG íŒŒì´í”„ë¼ì¸ ë°ëª¨\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        for i, query in enumerate(queries):\n",
        "            print(f\"\\\\nğŸ” ì¿¼ë¦¬ #{i+1}: {query}\")\n",
        "            print(\"-\" * 50)\n",
        "            \n",
        "            result = self.retrieve_and_format(query)\n",
        "            stats = result['stats']\n",
        "            \n",
        "            print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:\")\n",
        "            print(f\"  ì´ ë¬¸ì„œ: {stats['total_docs']}ê°œ\")\n",
        "            print(f\"  PNS ê´€ë ¨: {stats['pns_docs']}ê°œ\")\n",
        "            print(f\"  purchaseState í¬í•¨: {stats['purchasestate_docs']}ê°œ\")\n",
        "            print(f\"  PNS+purchaseState: {stats['both_docs']}ê°œ\")\n",
        "            print(f\"  ê´€ë ¨ì„± ì ìˆ˜: {stats['relevance_score']:.2f}\")\n",
        "            \n",
        "            # ìƒìœ„ 3ê°œ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°\n",
        "            print(f\"\\\\nğŸ“„ ìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "            for j, doc in enumerate(result['retrieved_docs'][:3]):\n",
        "                hierarchy = doc.metadata.get('title_hierarchy', 'Unknown')\n",
        "                is_both = doc.metadata.get('pns_purchasestate_both', False)\n",
        "                \n",
        "                print(f\"\\\\n  #{j+1} {'ğŸ¯' if is_both else 'ğŸ“„'}\")\n",
        "                print(f\"    ì œëª©: {hierarchy}\")\n",
        "                print(f\"    ë‚´ìš©: {doc.page_content[:100].replace(chr(10), ' ')}...\")\n",
        "            \n",
        "            # í’ˆì§ˆ í‰ê°€\n",
        "            if stats['both_docs'] >= 2:\n",
        "                print(f\"\\\\nâœ… ìš°ìˆ˜: PNS ì„¹ì…˜ ë‚´ purchaseState ë¬¸ì„œ {stats['both_docs']}ê°œ ê²€ìƒ‰ ì„±ê³µ!\")\n",
        "            elif stats['both_docs'] >= 1:\n",
        "                print(f\"\\\\nâš¡ ì–‘í˜¸: ì¼ë¶€ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ë¨ ({stats['both_docs']}ê°œ)\")\n",
        "            else:\n",
        "                print(f\"\\\\nâš ï¸  ê°œì„  í•„ìš”: ê´€ë ¨ ë¬¸ì„œ ë¶€ì¡±\")\n",
        "\n",
        "# ìµœì í™”ëœ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸\n",
        "rag_pipeline = OptimizedRAGPipeline(documents, best_strategy)\n",
        "rag_pipeline.setup_retriever()\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
        "test_queries = [\n",
        "    \"PNS ë©”ì‹œì§€ì˜ purchaseState ê°’ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\",\n",
        "    \"Payment Notification Serviceì—ì„œ purchaseStateëŠ” ì–´ë–¤ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ë‚˜ìš”?\",\n",
        "    \"ì›ìŠ¤í† ì–´ PNS ê·œê²©ì—ì„œ êµ¬ë§¤ ìƒíƒœ ì½”ë“œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "]\n",
        "\n",
        "# ë°ëª¨ ì‹¤í–‰\n",
        "rag_pipeline.demo_rag_search(test_queries)\n",
        "\n",
        "# ìµœì¢… ê²°ë¡ \n",
        "print(f\"\\\\nğŸ† ìµœì¢… ê²°ë¡ \")\n",
        "print(\"=\"*60)\n",
        "print(f\"âœ… ìµœì  ì „ëµ: {best_strategy}\")\n",
        "print(f\"âœ… PNS ì„¹ì…˜ ë‚´ purchaseState ê²€ìƒ‰ ë¬¸ì œ í•´ê²°\")\n",
        "print(f\"âœ… ê¸°ì¡´ ëŒ€ë¹„ ê²€ìƒ‰ í’ˆì§ˆ ëŒ€í­ í–¥ìƒ\")\n",
        "print(f\"âœ… ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ ì ìš© ì¤€ë¹„ ì™„ë£Œ\")\n",
        "\n",
        "print(f\"\\\\nğŸš€ í”„ë¡œë•ì…˜ ì ìš© ê°€ì´ë“œ:\")\n",
        "print(f\"1. MultiLevelSplittingStrategyë¡œ ë¬¸ì„œ ì „ì²˜ë¦¬\")\n",
        "print(f\"2. {best_strategy} Retriever ì‚¬ìš©\")\n",
        "print(f\"3. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í›„ì²˜ë¦¬ í•„í„°ë§ ì ìš©\")\n",
        "print(f\"4. PNS+purchaseState ë™ì‹œ í¬í•¨ ë¬¸ì„œ ìš°ì„ ìˆœìœ„ ë¶€ì—¬\")\n",
        "print(f\"5. ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° íŠœë‹\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
