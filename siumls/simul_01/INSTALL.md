# simul_01 í”„ë¡œì íŠ¸ ì„¤ì¹˜ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” simul_01 RAG ì‹¤í—˜ í”„ë¡œì íŠ¸ì˜ í™˜ê²½ ì„¤ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì„¤ì¹˜

### 1. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Linux/Mac:
source venv/bin/activate
# Windows:
# venv\Scripts\activate
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

#### CPU ì „ìš© í™˜ê²½
```bash
pip install -r requirements_simul.txt
```

#### GPU í™˜ê²½ (ê¶Œì¥)
```bash
pip install -r requirements_gpu.txt
```

## ğŸ”§ ìƒì„¸ ì„¤ì¹˜ ê°€ì´ë“œ

### í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸

```bash
# Python ë²„ì „ í™•ì¸ (3.8 ì´ìƒ ê¶Œì¥)
python --version

# pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip
```

### GPU í™˜ê²½ ì„¤ì • (ì„ íƒì‚¬í•­)

#### CUDA í™•ì¸
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# PyTorch GPU ì§€ì› í™•ì¸
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

#### GPU íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# CUDA 12.1ìš© PyTorch ì„¤ì¹˜
pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 --extra-index-url https://download.pytorch.org/whl/cu121
```

### Ollama ì„¤ì •

#### Ollama ì„œë²„ ì„¤ì¹˜
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# https://ollama.ai/download ì—ì„œ ë‹¤ìš´ë¡œë“œ
```

#### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# exaone3.5:latest ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull exaone3.5:latest
```

## ğŸ§ª ì„¤ì¹˜ í™•ì¸

### ê¸°ë³¸ í…ŒìŠ¤íŠ¸
```bash
# Python íŒ¨í‚¤ì§€ import í…ŒìŠ¤íŠ¸
python -c "
import langchain
import langchain_ollama
import faiss
import torch
import pandas
import matplotlib
print('âœ… ëª¨ë“  íŒ¨í‚¤ì§€ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤!')
"
```

### GPU í…ŒìŠ¤íŠ¸
```bash
# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
python -c "
import torch
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB')
else:
    print('CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.')
"
```

### Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
```bash
# Ollama ì„œë²„ ì—°ê²° í™•ì¸
python -c "
from langchain_ollama import OllamaEmbeddings
try:
    embeddings = OllamaEmbeddings(model='exaone3.5:latest')
    print('âœ… Ollama ì„œë²„ì— ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!')
except Exception as e:
    print(f'âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}')
"
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸

```bash
# í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸
ls -la simul_01/
# ì˜ˆìƒ íŒŒì¼ë“¤:
# - rag_experiment.py
# - gpu_optimized_rag.py
# - document_analyzer.py
# - result_analyzer.py
# - simple_test.py
# - check_tables.py
# - README.md
```

## ğŸš€ ì²« ì‹¤í–‰

### 1. ê¸°ë³¸ í…ŒìŠ¤íŠ¸
```bash
cd simul_01
python simple_test.py
```

### 2. GPU ìµœì í™” ì‹¤í—˜
```bash
python gpu_optimized_rag.py
```

### 3. ì „ì²´ ì‹¤í—˜
```bash
python rag_experiment.py
```

## âš ï¸ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. CUDA ì˜¤ë¥˜
```bash
# CUDA ë²„ì „ í™•ì¸
nvcc --version

# PyTorch ì¬ì„¤ì¹˜
pip uninstall torch torchvision
pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 --extra-index-url https://download.pytorch.org/whl/cu121
```

#### 2. Ollama ì—°ê²° ì˜¤ë¥˜
```bash
# Ollama ì„œë²„ ìƒíƒœ í™•ì¸
ollama list

# ì„œë²„ ì¬ì‹œì‘
sudo systemctl restart ollama
# ë˜ëŠ”
ollama serve
```

#### 3. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# GPU ë©”ëª¨ë¦¬ í™•ì¸
nvidia-smi

# ë°°ì¹˜ í¬ê¸° ì¡°ì • (ì½”ë“œì—ì„œ ìˆ˜ì •)
# batch_size = 16  # ë” ì‘ì€ ê°’ìœ¼ë¡œ ì¡°ì •
```

#### 4. íŒ¨í‚¤ì§€ ì¶©ëŒ
```bash
# ê°€ìƒí™˜ê²½ ì¬ìƒì„±
deactivate
rm -rf venv
python -m venv venv
source venv/bin/activate
pip install -r requirements_gpu.txt
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# ì‹¤ì‹œê°„ GPU ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ë©”ëª¨ë¦¬ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"
```

### ë°°ì¹˜ í¬ê¸° ì¡°ì •
- GPU ë©”ëª¨ë¦¬ 8GB ì´í•˜: `batch_size = 16`
- GPU ë©”ëª¨ë¦¬ 8GB ì´ìƒ: `batch_size = 32`
- GPU ë©”ëª¨ë¦¬ 16GB ì´ìƒ: `batch_size = 64`

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

1. **ë¡œê·¸ í™•ì¸**: ê° ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥
2. **í™˜ê²½ í™•ì¸**: Python ë²„ì „, CUDA ë²„ì „, íŒ¨í‚¤ì§€ ë²„ì „
3. **ë©”ëª¨ë¦¬ í™•ì¸**: GPU/CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
4. **ë„¤íŠ¸ì›Œí¬ í™•ì¸**: Ollama ì„œë²„ ì—°ê²° ìƒíƒœ

## ğŸ¯ ì„±ê³µ ì§€í‘œ

ì„¤ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ë‹¤ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:

- âœ… `python simple_test.py` ì‹¤í–‰ ì„±ê³µ
- âœ… purchaseState ê´€ë ¨ ì •ë³´ 31ê°œ ë°œê²¬
- âœ… GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥
- âœ… Ollama ëª¨ë¸ `exaone3.5:latest` ì‚¬ìš© ê°€ëŠ¥
- âœ… ì‹¤í—˜ ê²°ê³¼ JSON íŒŒì¼ ìƒì„±
- âœ… ì‹œê°í™” ì°¨íŠ¸ ìƒì„± 